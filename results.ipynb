{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "import time\n",
    "start_time = time.time()\n",
    "from copy import deepcopy, copy\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import shutil\n",
    "import os\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "# from featext2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "#matplotlib qt\n",
    "# inline (suitable for ipython only, shown inside browser!) or qt (suitable in general, shown in external window!)\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.mplot3d import Axes3D #, axes3d\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, ParameterGrid, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.decomposition import PCA, KernelPCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LassoCV, RandomizedLasso\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2, f_classif, mutual_info_classif, SelectFdr\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import datetime\n",
    "import urllib\n",
    "import tarfile\n",
    "# import joblib\n",
    "# from joblib import Parallel, delayed, Memory\n",
    "from tempfile import mkdtemp\n",
    "import copy_reg\n",
    "import types\n",
    "import itertools\n",
    "from itertools import compress\n",
    "from collections import Counter\n",
    "\n",
    "#import multiprocessing\n",
    "def _pickle_method(m):\n",
    "    if m.im_self is None:\n",
    "        return getattr, (m.im_class, m.im_func.func_name)\n",
    "    else:\n",
    "        return getattr, (m.im_self, m.im_func.func_name)\n",
    "copy_reg.pickle(types.MethodType, _pickle_method)\n",
    "\n",
    "h = .2  # step size in the mesh\n",
    "names = [\"NearNb\", \"RBFSVM1\", \"NaiveBayes\", \"MLP1\", \"Log.Regr\", \"RandFor\", \"AdaBoost\", \"EnsembleMLP\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    SVC(gamma='auto', C=1),\n",
    "    MLPClassifier(solver='lbfgs',alpha=1e-4,hidden_layer_sizes=(10,10),random_state=1,verbose=True),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "parameters_clf = [{'n_neighbors':range(3,10)},\n",
    "              {'kernel':['rbf'], 'C':[0.01,0.1,1,10,100,1000]},\n",
    "              {'solver':['lbfgs'], 'alpha':[1e-5,1e-2], 'hidden_layer_sizes':[(10,10),(50,50),(100,100)]},\n",
    "              {'max_depth':[4,7,10,20],'n_estimators':[5,10,20],'max_features':[20,35,50]},\n",
    "              {'solver':['lbfgs'], 'alpha':[1e-5], 'hidden_layer_sizes':[(len(names)-1,len(names)-1),(len(names)-1,2)]}\n",
    "             ]\n",
    "makepipe_parameters_clf = [{'classifier__'+key:p[key] for key in p} for p in parameters_clf]\n",
    "makepipe_parameters_clf += [{'feature_selection__k': (750,500,100), 'feature_selection__score_func': [mutual_info_classif]},\n",
    "                            {'decomp__n_components': (100,50)}]\n",
    "metric = ['accuracy','f1']\n",
    "dataset = 0 # all datasets (0), dataset 1-2 (1), dataset 3 (2), dataset4 (3)\n",
    "download = 1 # Download pre-computed (1) data or compute them anew (0)\n",
    "window = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pipe_clf(scaler,feature_selection,decomp,clf):\n",
    "    order = 1\n",
    "# order = 1 : first perform feature selection and then apply PCA\n",
    "# order = 0 : first apply PCA and then reduce the transformed features\n",
    "    if order:\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                    ('feature_selection', feature_selection),\n",
    "                    ('decomp', decomp),         \n",
    "                    ('classifier', clf) ])\n",
    "#     else:\n",
    "#         pipeline = Pipeline([('scaler', scaler),\n",
    "#                     ('decomp', decomp ),                 \n",
    "#                     ('feature_selection', feature_selection),        \n",
    "#                     ('classifier', clf) ])\n",
    "    return pipeline\n",
    "###########################################################################################\n",
    "def make_pipe(scaler,feature_selection,decomp,order):\n",
    "    if order:\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                    ('feature_selection', feature_selection),\n",
    "                    ('decomp', decomp),         \n",
    "                     ])\n",
    "    else:\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                    ('decomp', decomp ),                 \n",
    "                    ('feature_selection', feature_selection),        \n",
    "                     ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feat_id(feat_ind, printit = 0): \n",
    "    sample_window = 1024\n",
    "    ##  features:                                                                                  ||      if         ##\n",
    "##  |----------> time domain      :                                                            || samples = 1024  ##\n",
    "##  |------------|---> phinyomark : 11+3{shist} -----------------------------> = 14+0.0samples ||             14  ##\n",
    "##  |------------|---> golz       : 10+samples{acrol} -----------------------> = 10+1.0samples ||           1034  ##\n",
    "##  |----------> frequency domain :                                                                               ##\n",
    "##  |------------|---> phinyomark : 3{arco}+4{mf}+3(samples/2+1){RF,IF} -----> =  9+1.0samples ||           1033  ##\n",
    "##  |------------|---> golz       : 2(samples/2+1){AF,PF} -------------------> =  2+1.0samples ||           1027  ##\n",
    "##  |------------|--------|-------alltogether--------------------------------> = 35+3.0samples || numfeat = 3108  ##\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "    norm_time_phin = range(0,14)\n",
    "    norm_freq_phin = range(norm_time_phin[-1] + 1, norm_time_phin[-1] + 9 + sample_window + 1)\n",
    "    norm_time_golz = range(norm_freq_phin[-1] + 1, norm_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    norm_freq_golz = range(norm_time_golz[-1] + 1, norm_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    norm_time_feats = norm_time_phin + norm_time_golz\n",
    "    norm_freq_feats = norm_freq_phin + norm_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    norm_feats = norm_time_feats + norm_freq_feats\n",
    "\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "#     np.arange(norm_feats[-1]+1,norm_feats[-1]+1+len(norm_feats))\n",
    "    disp = norm_feats[-1]+1\n",
    "    ftfn_time_phin = range(disp ,disp + 14)\n",
    "    ftfn_freq_phin = range(ftfn_time_phin[-1] + 1, ftfn_time_phin[-1] + 9 + sample_window + 1)\n",
    "    ftfn_time_golz = range(ftfn_freq_phin[-1] + 1, ftfn_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    ftfn_freq_golz = range(ftfn_time_golz[-1] + 1, ftfn_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    ftfn_time_feats = ftfn_time_phin + ftfn_time_golz\n",
    "    ftfn_freq_feats = ftfn_freq_phin + ftfn_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    ftfn_feats = ftfn_time_feats + ftfn_freq_feats\n",
    "\n",
    "    # create the final \"reference dictionary\"\n",
    "    id_list = [np.zeros((len(ftfn_feats + norm_feats),1)) for i in range(3)] #3 np.arrays, id_list[0] = level 1 etc\n",
    "    id_list[0][:norm_feats[-1]+1] = 0 # 0 signifies norm / 1 signifies ft/fn\n",
    "    id_list[0][norm_feats[-1]+1:] = 1\n",
    "\n",
    "    id_list[1][:norm_time_phin[-1]+1] = 0 #0 signifies time / 1 signifies freq\n",
    "    id_list[1][norm_time_phin[-1]+1:norm_freq_phin[-1]+1] = 1\n",
    "    id_list[1][norm_freq_phin[-1]+1:norm_time_golz[-1]+1] = 0\n",
    "    id_list[1][norm_time_golz[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[1][norm_freq_golz[-1]+1:ftfn_time_phin[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_phin[-1]+1:ftfn_freq_phin[-1]+1] = 1\n",
    "    id_list[1][ftfn_freq_phin[-1]+1:ftfn_time_golz[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_golz[-1]+1:] = 1\n",
    "\n",
    "    id_list[2][:norm_freq_phin[-1]+1] = 0 #0 signifies phinyomark / 1 signifies golz\n",
    "    id_list[2][norm_freq_phin[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[2][norm_freq_golz[-1]+1:ftfn_freq_phin[-1]+1] = 0\n",
    "    id_list[2][ftfn_freq_phin[-1]+1:] = 1 \n",
    "    \n",
    "    full_path_id = [np.zeros((len(feat_ind),5)) for i in range(len(feat_ind))]\n",
    "   \n",
    "    for ind, val in enumerate(feat_ind):\n",
    "\n",
    "        full_path_id[ind] = [val, id_list[2][val], id_list[1][val], id_list[0][val]]\n",
    "\n",
    "        if (printit==1):\n",
    "            if(full_path_id[ind][1]==0):\n",
    "                lvl3 = 'Phin'\n",
    "            else:\n",
    "                lvl3 = 'Golz'\n",
    "            if(full_path_id[ind][2]==0):\n",
    "                lvl2 = 'Time'\n",
    "            else:\n",
    "                lvl2 = 'Freq'\n",
    "            if(full_path_id[ind][3]==0):\n",
    "                lvl1 = 'Norm'\n",
    "            else:\n",
    "                lvl1 = 'Ft/Fn'\n",
    "            print(feat_ind[ind],featnames[val%(norm_feats[-1]+1)],lvl3,lvl2,lvl1)\n",
    "    \n",
    "    return(full_path_id)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feat_occ(feat_masks):\n",
    "    #get the number of occurences for each feature after SelectKbest\n",
    "#     print(\"If it ain't working, just make sure you're adding the lists instead of concatenating them,\")\n",
    "#     print(\"if the input isn't a single list you'll get the unhashable error\")\n",
    "    feat_occ = Counter(feat_masks)\n",
    "    return feat_occ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Nested_cv:\n",
    "    def __init__(self, n_outer_folds = 3, n_inner_folds = 3, n_top =1, state = 42):\n",
    "        self.n_outer_folds = n_outer_folds\n",
    "        self.n_inner_folds = n_inner_folds\n",
    "        self.n_top = n_top\n",
    "        self.state = state\n",
    "#         print(\"constructor %d\" %self.state)\n",
    "                                        \n",
    "    def set_pipe(self, pip_steps, pip_params):\n",
    "        n_steps = len(pip_steps)\n",
    "        if n_steps == 3:\n",
    "            self.pipe = make_pipe(scaler = pip_steps[0], feature_selection = pip_steps[1], decomp = pip_steps[2])\n",
    "            self.params = pip_params\n",
    "        if n_steps == 4:\n",
    "            self.pipe = make_pipe_clf(scaler = pip_steps[0], feature_selection = pip_steps[1], decomp = pip_steps[2], clf = pip_steps[3])\n",
    "            self.params = pip_params\n",
    "        else:\n",
    "            print (\"Number of steps gotta be either 3 or 4, you inserted %d.\" %n_steps)\n",
    "        return self.pipe\n",
    "        \n",
    "    def fit(self, x_tot, y_tot, verbose = 0):\n",
    "        self.verbose = verbose\n",
    "#         print(\"fit %d\" %self.state)\n",
    "        if self.n_top >1 :\n",
    "            print (\"ACHTUNG! You need to use fit2 for multiple best models!\")\n",
    "            self.fit2(x_tot,y_tot)\n",
    "        else:\n",
    "            self.outer_cv = StratifiedKFold(n_splits = self.n_outer_folds, shuffle = True, random_state = self.state)\n",
    "            self.inner_cv = StratifiedKFold(n_splits = self.n_inner_folds, shuffle = True, random_state = self.state)\n",
    "            self.grid = GridSearchCV(self.pipe, self.params, cv = self.inner_cv, verbose = self.verbose)       \n",
    "            self.score = cross_val_score(self.grid, X = x_tot, y = y_tot, cv = self.outer_cv, verbose = self.verbose)\n",
    "\n",
    "    def get_outer_scores(self):\n",
    "        return self.score\n",
    "    \n",
    "    def get_mean_score(self):\n",
    "        self.mean_score = self.score.mean()\n",
    "        print (\"Mean score of %d outer folds : %f\" %(self.n_outer_folds, self.mean_score ))\n",
    "        return self.mean_score\n",
    "    \n",
    "#     def combinations(self):\n",
    "#         self.comb = 1\n",
    "#         for self.key in self.params.keys():\n",
    "#             self.comb =self.comb*len(self.params[self.key])\n",
    "#         return self.comb\n",
    "    \n",
    "    def get_feat_scores(self):\n",
    "        return self.total_feats\n",
    "    \n",
    "    def get_best_features(self):\n",
    "        print(self.best_feat_ind)\n",
    "        return self.best_feat_ind\n",
    "    \n",
    "    def print_feat_scores(self):\n",
    "        self.norm_total_feats = (self.total_feats)/(self.n_inner_folds * self.n_top)\n",
    "        plt.figure()\n",
    "        self.rel_score = plt.bar(range(len(self.total_feats)),self.norm_total_feats)\n",
    "        plt.xlabel(\"Features\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def repeated_cv(self,x_tot, y_tot, num_trials):\n",
    "        self.repeated = np.zeros(num_trials)\n",
    "        self.rep_feat_scores = np.zeros(x_tot.shape[1])\n",
    "        self.num_trials = num_trials\n",
    "        self.state +=1\n",
    "        for st in range(self.num_trials):\n",
    "            self.state +=1\n",
    "            self.fit(x_tot, y_tot)\n",
    "#             print(\"repeated %d\" %self.state)\n",
    "            self.out = self.get_outer_scores()\n",
    "            self.rep_feat_scores += self.get_feat_scores()\n",
    "            self.repeated[st] = self.out.mean()\n",
    "            \n",
    "        plt.figure()\n",
    "        self.rep_sc_plot = plt.bar(range(num_trials),self.repeated)\n",
    "        plt.xlabel(\"Individual trial #\")\n",
    "        plt.ylabel(\"Outer mean scores\")\n",
    "        plt.show()\n",
    "    \n",
    "    def print_rep_feat_scores(self):\n",
    "        plt.figure()\n",
    "        self.norm_rep_feats = (self.rep_feat_scores)/(self.n_inner_folds*self.n_top*self.num_trials)\n",
    "        self.rel_score = plt.bar(range(len(self.total_feats)),self.norm_rep_feats)\n",
    "        plt.xlabel(\"Features\")\n",
    "        plt.ylabel(\"Feature Score\")\n",
    "        plt.show()\n",
    "        \n",
    "    def get_rep_feat_scores(self):\n",
    "        return self.rep_feat_scores\n",
    "        \n",
    "    def fit2(self,x_tot, y_tot):\n",
    "        #the \"handwritten\" implementation\n",
    "        self.total_feats = np.zeros(x_tot.shape[1])\n",
    "        self.classifiers= list(ParameterGrid(self.params))\n",
    "        self.outer_scores = np.zeros((self.n_top, self.n_outer_folds))\n",
    "#         self.ncomp = self.params['decomp__n_components']\n",
    "#         self.best_feat_ind = []\n",
    "        self.best_pipes = [[],[]]\n",
    "        self.outer_cv = StratifiedKFold(n_splits = self.n_outer_folds, shuffle = True, random_state = self.state)\n",
    "        self.inner_cv = StratifiedKFold(n_splits = self.n_inner_folds, shuffle = True, random_state = self.state)\n",
    "        self.outer = self.outer_cv.split(x_tot,y_tot)\n",
    "        for self.fold_out, (self.train_ind_out,self.test_ind_out) in enumerate(self.outer):\n",
    "            top_models = []\n",
    "            if self.verbose>0 :\n",
    "                print(\"Outer loop %d/%d\" %((self.fold_out + 1), self.n_outer_folds))\n",
    "        # split the dataset \n",
    "            self.x_trn_out, self.x_tst_out = x_tot[self.train_ind_out], x_tot[self.test_ind_out]\n",
    "            self.y_trn_out, self.y_tst_out = y_tot[self.train_ind_out], y_tot[self.test_ind_out]  \n",
    "            \n",
    "            self.inner_scores = np.zeros((len(self.classifiers),self.n_inner_folds))\n",
    "            self.inner_mean_scores = np.zeros(len(self.classifiers))\n",
    "            \n",
    "            for self.cl_ind, self.clf in enumerate(self.classifiers):\n",
    "                self.inner = self.inner_cv.split(self.x_trn_out, self.y_trn_out)\n",
    "                self.nfeat = self.classifiers[self.cl_ind]['feature_selection__k']\n",
    "                self.best_feat_ind = np.zeros((self.n_top, self.nfeat))\n",
    "\n",
    "\n",
    "                for self.fold_in, (self.train_ind_in, self.test_ind_in) in enumerate(self.inner): \n",
    "                    if self.verbose>0 :\n",
    "                        print(\"Inner fold %d/%d\" % ((self.fold_in + 1), self.n_inner_folds ))\n",
    "                    # split the datasets for the inner cv \n",
    "                    self.x_trn_in, self.x_tst_in = self.x_trn_out[self.train_ind_in], self.x_trn_out[self.test_ind_in]\n",
    "                    self.y_trn_in, self.y_tst_in = self.y_trn_out[self.train_ind_in], self.y_trn_out[self.test_ind_in]\n",
    "                    self.pip = self.pipe.set_params(**self.clf)\n",
    "                    self.pip.fit(self.x_trn_in,self.y_trn_in)\n",
    "                    self.inner_scores[self.cl_ind][self.fold_in] = self.pip.score(self.x_tst_in, self.y_tst_in)\n",
    "\n",
    "            # get the mean performance for every classifier\n",
    "            self.inner_mean_scores = np.mean(self.inner_scores, axis = 1)\n",
    "#             print('\\n',self.inner_mean_scores)\n",
    "\n",
    "            # sort the scores, low -> high \n",
    "            self.sorted_inds = self.inner_mean_scores.argsort()\n",
    "            self.sorted_scores = self.inner_mean_scores[self.sorted_inds]\n",
    "\n",
    "            print (\"Best %d models for outer fold %d are: \\n \" %(self.n_top, (self.fold_out+1)))\n",
    "\n",
    "#             get the inds of best performing models\n",
    "            self.temp2 = 0 #iterates over n_top models\n",
    "            for self.temp_ind in range(-1, -(self.n_top +1), -1):\n",
    "                self.actual_ind = self.sorted_inds[self.temp_ind]\n",
    "                self.best_pipes[1].append(self.classifiers[self.actual_ind]) \n",
    "                self.best_pipes[0].append(self.fold_out)\n",
    "                print(\"model no.%d \"%(self.actual_ind + 1))\n",
    "                print(self.classifiers[self.actual_ind])\n",
    "                #print the top features selected\n",
    "                self.best_fs = self.pipe.set_params(**self.classifiers[self.actual_ind]).named_steps['feature_selection']\n",
    "#                 best_fs = pipeline[actual_ind].named_steps['feature_selection']\n",
    "                self.best_fs_indd = self.best_fs.get_support(indices = True)\n",
    "#                 print(self.best_fs_indd)\n",
    "                self.pipe_fs_unsorted = self.best_fs.scores_\n",
    "                self.fs_inds = self.pipe_fs_unsorted.argsort()\n",
    "#                 print(self.fs_inds)\n",
    "                self.pipe_fs = self.pipe_fs_unsorted[self.fs_inds]\n",
    "                self.temp3 = 0 # temp3 = 0:number of features\n",
    "               \n",
    "                for self.temp_ind2 in range(-1, -(self.nfeat +1), -1):         \n",
    "                    self.best_feat_ind[self.temp2][self.temp3]=self.fs_inds[self.temp_ind2]\n",
    "                    self.total_feats[self.fs_inds[self.temp_ind2]]+=1 # feature scores \n",
    "                    self.temp3+=1\n",
    "#                 print(self.total_feats)\n",
    "                #fit the best classifier on the outer test data\n",
    "                self.best_pip = self.pipe.set_params(**self.classifiers[self.actual_ind])\n",
    "                \n",
    "                self.best_pip.fit(self.x_trn_out, self.y_trn_out)\n",
    "                \n",
    "                #get the outer score \n",
    "                self.outer_scores[self.temp2, self.fold_out] = self.best_pip.score(self.x_tst_out, self.y_tst_out)\n",
    "                print(\"Inner score: %f VS Outer score: %f \\n\" %(self.inner_mean_scores[self.actual_ind], self.outer_scores[self.temp2, self.fold_out]))\n",
    "                print (\"----------------------------------------------------------\")\n",
    "                self.temp2+=1\n",
    "\n",
    "\n",
    "#             print(\"Features selected: \\n\")\n",
    "        #     print(best_feat_ind.sort())     \n",
    "#             print(self.best_feat_ind)\n",
    "        # print(outer_scores)  \n",
    "        # print(best_pipes)\n",
    "        self.score = self.outer_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## Feature Names ###########################################################\n",
    "####################################################################################################################\n",
    "##  features:                                                                                  ||      if         ##\n",
    "##  |----------> time domain      :                                                            || samples = 1024  ##\n",
    "##  |------------|---> phinyomark : 11+3{shist} -----------------------------> = 14+0.0samples ||             14  ##\n",
    "##  |------------|---> golz       : 10+samples{acrol} -----------------------> = 10+1.0samples ||           1034  ##\n",
    "##  |----------> frequency domain :                                                                               ##\n",
    "##  |------------|---> phinyomark : 3{arco}+4{mf}+3(samples/2+1){RF,IF} -----> =  9+1.0samples ||           1033  ##\n",
    "##  |------------|---> golz       : 2(samples/2+1){AF,PF} -------------------> =  2+1.0samples ||           1027  ##\n",
    "##  |------------|--------|-------alltogether--------------------------------> = 35+3.0samples || numfeat = 3108  ##\n",
    "####################################################################################################################\n",
    "## Time Domain Phinyomark feats\n",
    "featnames = ['intsgnl', 'meanabs', 'meanabsslp', 'ssi', 'var', 'rms', 'rng', 'wavl', 'zerox', 'ssc', 'wamp', \n",
    "             'shist1', 'shist2', 'shist3']                                                   # 11+3{shist}\n",
    "## Frequency Domain Phinyomark feats\n",
    "featnames += ['arco1', 'arco2', 'arco3', 'mnf', 'mdf', 'mmnf', 'mmdf']                       # 3{arco}+4{mf}\n",
    "featnames += ['reFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{RF}\n",
    "featnames += ['imFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{IF}\n",
    "## Time Domain Golz feats\n",
    "featnames += ['meanv', 'stdr', 'mx', 'rngx', 'rngy', 'med', 'hjorth', 'sentr', 'se', 'ssk']  # 10\n",
    "featnames += ['acrol{:04d}'.format(i) for i in range(window)]                                # samples{acrol}\n",
    "## Frequency Domain Golz feats\n",
    "featnames += ['amFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{AF}\n",
    "featnames += ['phFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{PF}\n",
    "# featnames += ['ffaf']                                                                        # 1{ffaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = np.load('newfeatures_newdata_NOsample_1024_20_10_10000_XYsplit.npz')\n",
    "X = datasets['Xsp']\n",
    "Y = datasets['Ysp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8902, 3107), (8902, 3107), (8902, 6214), (8902, 3107), (8902, 3107), (8902, 6214), (8898, 3107), (8898, 3107), (8898, 6214)]\n"
     ]
    }
   ],
   "source": [
    "print([ X[i][j].shape for i in range(len(X)) for j in range(len(X[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.895564, total= 6.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  6.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3302bd8c3db1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpipe_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"=============================================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mscore_func_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_func_ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/mutual_info_.pyc\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     return _estimate_mi(X, y, discrete_features, True, n_neighbors,\n\u001b[0;32m--> 438\u001b[0;31m                         copy, random_state)\n\u001b[0m",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/mutual_info_.pyc\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     mi = [_compute_mi(x, y, discrete_feature, discrete_target) for\n\u001b[0;32m--> 285\u001b[0;31m           x, discrete_feature in moves.zip(_iterate_columns(X), discrete_mask)]\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/mutual_info_.pyc\u001b[0m in \u001b[0;36m_compute_mi\u001b[0;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx_discrete\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my_discrete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/feature_selection/mutual_info_.pyc\u001b[0m in \u001b[0;36m_compute_mi_cd\u001b[0;34m(c, d, n_neighbors)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kd_tree'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0mm_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ifoundacarrot/.local/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mradius_neighbors\u001b[0;34m(self, X, radius, return_distance)\u001b[0m\n\u001b[1;32m    619\u001b[0m                     \"or set algorithm='brute'\" % self._fit_method)\n\u001b[1;32m    620\u001b[0m             results = self._tree.query_radius(X, radius,\n\u001b[0;32m--> 621\u001b[0;31m                                               return_distance=return_distance)\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# i: iterating over finger, j: over featureset \n",
    "# (consider keeping only the second featureset and discarding the rest to save some space)\n",
    "# Performing cross validation for each finger on the second feature set \n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "# set the pipeline\n",
    "# def make_pipe_clf(scaler,feature_selection,decomp,clf):\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "scores = []\n",
    "for i in range(len(X)):\n",
    "    data = deepcopy(X[i][2])\n",
    "    print(i)\n",
    "    labels = deepcopy(Y[i])\n",
    "    for pipe in pipe_list:\n",
    "        score = cross_val_score(estimator = pipe, X = data, y = labels, cv = cv, verbose = 100)\n",
    "        scores.append(score)\n",
    "        print (\"=============================================================\")\n",
    "        print(\"Datasets : %d, classifier : %0.4s, 5-fold avg score = %f\" %(i, pipe.named_steps['classifier'], np.mean(score)))\n",
    "        print(score)\n",
    "        print (\"=============================================================\")\n",
    "        \n",
    "# print pipe_list[1].named_steps['classifier']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.887205, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.924115, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.9min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.905565, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.934233, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.7min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.881956, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.1min finished\n",
      "=============================================================\n",
      "Object : 0, classifier : KNei, 5-fold avg score = 0.906615\n",
      "[ 0.88720539  0.92411467  0.90556492  0.93423272  0.88195616]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.932660, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.913997, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.951096, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.2min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.961214, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.7min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.890388, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min finished\n",
      "=============================================================\n",
      "Object : 0, classifier : SVC(, 5-fold avg score = 0.929871\n",
      "[ 0.93265993  0.91399663  0.95109612  0.96121417  0.89038786]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.957912, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.939292, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.905565, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.2min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.981450, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.915683, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.0min finished\n",
      "=============================================================\n",
      "Object : 0, classifier : MLPC, 5-fold avg score = 0.939980\n",
      "[ 0.95791246  0.93929174  0.90556492  0.98145025  0.91568297]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.919192, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.927487, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.954469, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.2min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.989882, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.919056, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.2min finished\n",
      "=============================================================\n",
      "Object : 0, classifier : Rand, 5-fold avg score = 0.942017\n",
      "[ 0.91919192  0.92748735  0.9544688   0.98988196  0.91905565]\n",
      "=============================================================\n",
      "1\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.627946, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.895447, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.767285, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.7min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.893761, total= 3.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 10.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.902192, total= 4.2min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 15.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 15.0min finished\n",
      "=============================================================\n",
      "Object : 1, classifier : KNei, 5-fold avg score = 0.817326\n",
      "[ 0.62794613  0.89544688  0.76728499  0.89376054  0.90219224]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.638047, total= 4.2min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.2min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.947723, total= 3.5min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.770658, total= 2.6min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 10.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.890388, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 12.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.883642, total= 2.2min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 14.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 14.9min finished\n",
      "=============================================================\n",
      "Object : 1, classifier : SVC(, 5-fold avg score = 0.826092\n",
      "[ 0.63804714  0.94772344  0.77065767  0.89038786  0.8836425 ]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. , score=0.784512, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.967960, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.777403, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.917369, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.920742, total= 2.4min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.9min finished\n",
      "=============================================================\n",
      "Object : 1, classifier : MLPC, 5-fold avg score = 0.873597\n",
      "[ 0.78451178  0.96795953  0.77740304  0.91736931  0.92074199]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.969697, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.966273, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.8min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.772344, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.903879, total= 2.5min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.5min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.915683, total= 2.3min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.9min finished\n",
      "=============================================================\n",
      "Object : 1, classifier : Rand, 5-fold avg score = 0.905575\n",
      "[ 0.96969697  0.96627319  0.77234401  0.90387858  0.91568297]\n",
      "=============================================================\n",
      "2\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.764310, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.951096, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.856661, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.961214, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.770658, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min finished\n",
      "=============================================================\n",
      "Object : 2, classifier : KNei, 5-fold avg score = 0.860788\n",
      "[ 0.76430976  0.95109612  0.85666105  0.96121417  0.77065767]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.695286, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.929174, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.905565, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.984823, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.775717, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min finished\n",
      "=============================================================\n",
      "Object : 2, classifier : SVC(, 5-fold avg score = 0.858113\n",
      "[ 0.6952862   0.92917369  0.90556492  0.98482293  0.77571669]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.818182, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.946037, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.915683, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.964587, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.812816, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min finished\n",
      "=============================================================\n",
      "Object : 2, classifier : MLPC, 5-fold avg score = 0.891461\n",
      "[ 0.81818182  0.9460371   0.91568297  0.96458685  0.81281619]\n",
      "=============================================================\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.966330, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.974705, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.915683, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.984823, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................. , score=0.770658, total= 2.0min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.1min finished\n",
      "=============================================================\n",
      "Object : 2, classifier : Rand, 5-fold avg score = 0.922440\n",
      "[ 0.96632997  0.97470489  0.91568297  0.98482293  0.77065767]\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# cross-validate on the different objects using the dataset from both fingers\n",
    "data_X = deepcopy(X[2][2]) # choose the featureset\n",
    "data_Y = deepcopy(Y[2])\n",
    "surfaces = np.split(data_X,3)\n",
    "surf_labels = np.split(data_Y,3)\n",
    "\n",
    "cv = KFold(n_splits=5,random_state=42)\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "scores = []\n",
    "\n",
    "for surf_ind, surf_data in enumerate(surfaces):\n",
    "    print(surf_ind)\n",
    "    data = surf_data\n",
    "    labels = surf_labels[surf_ind]\n",
    "    for pipe in pipe_list:\n",
    "        score = cross_val_score(estimator = pipe, X = data, y = labels, cv = cv, verbose = 100)\n",
    "        scores.append(score)\n",
    "        print (\"=============================================================\")\n",
    "        print(\"Object : %d, classifier : %0.4s, 5-fold avg score = %f\" %(surf_ind, pipe.named_steps['classifier'], np.mean(score)))\n",
    "        print(score)\n",
    "        print (\"=============================================================\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on surface no. 0\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0 with KNei\n",
      "[[ 0.92158134  0.07841866]\n",
      " [ 0.20660576  0.79339424]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.92      0.87      1543\n",
      "        1.0       0.90      0.79      0.84      1423\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0 with KNei\n",
      "[[ 0.92875318  0.07124682]\n",
      " [ 0.28766141  0.71233859]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.93      0.85      1572\n",
      "        1.0       0.90      0.71      0.79      1394\n",
      "\n",
      "avg / total       0.84      0.83      0.82      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0 with SVC(\n",
      "[[ 0.96759559  0.03240441]\n",
      " [ 0.14617006  0.85382994]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.97      0.92      1543\n",
      "        1.0       0.96      0.85      0.90      1423\n",
      "\n",
      "avg / total       0.92      0.91      0.91      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0 with SVC(\n",
      "[[ 0.99236641  0.00763359]\n",
      " [ 0.2482066   0.7517934 ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.99      0.90      1572\n",
      "        1.0       0.99      0.75      0.85      1394\n",
      "\n",
      "avg / total       0.90      0.88      0.88      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0 with MLPC\n",
      "[[ 0.84251458  0.15748542]\n",
      " [ 0.02740689  0.97259311]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.84      0.90      1543\n",
      "        1.0       0.85      0.97      0.91      1423\n",
      "\n",
      "avg / total       0.91      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0 with MLPC\n",
      "[[ 0.89440204  0.10559796]\n",
      " [ 0.11119082  0.88880918]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.89      0.90      1572\n",
      "        1.0       0.88      0.89      0.89      1394\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 0 with Rand\n",
      "[[ 0.92093325  0.07906675]\n",
      " [ 0.12930429  0.87069571]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.92      0.90      1543\n",
      "        1.0       0.91      0.87      0.89      1423\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 0 with Rand\n",
      "[[ 0.97010178  0.02989822]\n",
      " [ 0.17001435  0.82998565]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.97      0.91      1572\n",
      "        1.0       0.96      0.83      0.89      1394\n",
      "\n",
      "avg / total       0.91      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 1\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1 with KNei\n",
      "[[ 0.99085565  0.00914435]\n",
      " [ 0.1728223   0.8271777 ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.99      0.92      1531\n",
      "        1.0       0.99      0.83      0.90      1435\n",
      "\n",
      "avg / total       0.92      0.91      0.91      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1 with KNei\n",
      "[[ 0.94338422  0.05661578]\n",
      " [ 0.276901    0.723099  ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.94      0.86      1572\n",
      "        1.0       0.92      0.72      0.81      1394\n",
      "\n",
      "avg / total       0.85      0.84      0.84      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1 with SVC(\n",
      "[[ 0.96080993  0.03919007]\n",
      " [ 0.14494774  0.85505226]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.96      0.92      1531\n",
      "        1.0       0.95      0.86      0.90      1435\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1 with SVC(\n",
      "[[ 0.9980916   0.0019084 ]\n",
      " [ 0.29626973  0.70373027]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      1.00      0.88      1572\n",
      "        1.0       1.00      0.70      0.83      1394\n",
      "\n",
      "avg / total       0.89      0.86      0.86      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1 with MLPC\n",
      "[[ 0.98563031  0.01436969]\n",
      " [ 0.12055749  0.87944251]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.99      0.94      1531\n",
      "        1.0       0.98      0.88      0.93      1435\n",
      "\n",
      "avg / total       0.94      0.93      0.93      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1 with MLPC\n",
      "[[ 0.97010178  0.02989822]\n",
      " [ 0.20301291  0.79698709]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.97      0.90      1572\n",
      "        1.0       0.96      0.80      0.87      1394\n",
      "\n",
      "avg / total       0.90      0.89      0.89      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 1 with Rand\n",
      "[[ 0.91378184  0.08621816]\n",
      " [ 0.07874564  0.92125436]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.91      0.92      1531\n",
      "        1.0       0.91      0.92      0.92      1435\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 1 with Rand\n",
      "[[ 0.93765903  0.06234097]\n",
      " [ 0.1384505   0.8615495 ]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      0.94      0.91      1572\n",
      "        1.0       0.92      0.86      0.89      1394\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n",
      "Training on surface no. 2\n",
      "Fitting classifier no. 0...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2 with KNei\n",
      "[[ 0.910516    0.089484  ]\n",
      " [ 0.11149826  0.88850174]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.91      0.90      1531\n",
      "        1.0       0.90      0.89      0.90      1435\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2 with KNei\n",
      "[[ 0.8198315   0.1801685 ]\n",
      " [ 0.08924807  0.91075193]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.82      0.86      1543\n",
      "        1.0       0.82      0.91      0.86      1423\n",
      "\n",
      "avg / total       0.87      0.86      0.86      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 1...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2 with SVC(\n",
      "[[ 0.86348792  0.13651208]\n",
      " [ 0.08222997  0.91777003]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.86      0.89      1531\n",
      "        1.0       0.86      0.92      0.89      1435\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2966\n",
      "\n",
      "=============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "Trained on 2 with SVC(\n",
      "[[ 0.78742709  0.21257291]\n",
      " [ 0.04848911  0.95151089]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.79      0.86      1543\n",
      "        1.0       0.80      0.95      0.87      1423\n",
      "\n",
      "avg / total       0.88      0.87      0.87      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 2...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2 with MLPC\n",
      "[[ 0.8739386  0.1260614]\n",
      " [ 0.1184669  0.8815331]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.87      0.88      1531\n",
      "        1.0       0.87      0.88      0.87      1435\n",
      "\n",
      "avg / total       0.88      0.88      0.88      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2 with MLPC\n",
      "[[ 0.8250162   0.1749838 ]\n",
      " [ 0.09908644  0.90091356]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.83      0.86      1543\n",
      "        1.0       0.83      0.90      0.86      1423\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2966\n",
      "\n",
      "=============================================================\n",
      "Fitting classifier no. 3...\n",
      "...done fitting\n",
      "=============================================================\n",
      "Trained on 2 with Rand\n",
      "[[ 0.87067276  0.12932724]\n",
      " [ 0.06829268  0.93170732]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.87      0.90      1531\n",
      "        1.0       0.87      0.93      0.90      1435\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2966\n",
      "\n",
      "=============================================================\n",
      "=============================================================\n",
      "Trained on 2 with Rand\n",
      "[[ 0.78548283  0.21451717]\n",
      " [ 0.04567814  0.95432186]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.79      0.86      1543\n",
      "        1.0       0.80      0.95      0.87      1423\n",
      "\n",
      "avg / total       0.88      0.87      0.87      2966\n",
      "\n",
      "=============================================================\n",
      "If it ain't working, just make sure you're adding the lists instead of concatenating them,\n",
      "if the input isn't a single list you'll get the unhashable error\n",
      "CPU times: user 16min 1s, sys: 27 s, total: 16min 28s\n",
      "Wall time: 15min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# validate between the different objects using the dataset from both fingers\n",
    "# Dataset used : Both fingers \n",
    "# Featureset used : Ft/Fn\n",
    "# Version 1: keep alternatively one for training and test on the rest\n",
    "\n",
    "\n",
    "data_X = deepcopy(X[2][1]) \n",
    "data_Y = deepcopy(Y[2])\n",
    "surfaces = np.split(data_X,3)\n",
    "surf_labels = np.split(data_Y,3) \n",
    "feat_mask = []\n",
    "\n",
    "scaler = StandardScaler() ; featsel = SelectKBest(k=1000,score_func= mutual_info_classif)\n",
    "decomp = PCA(n_components=20)\n",
    "pipe_list = [make_pipe_clf(scaler,featsel, decomp, classifiers[i]) for i in range(len(classifiers))]\n",
    "\n",
    "for surf_ind, surf_dat in enumerate(surfaces):\n",
    "    print(\"Training on surface no. %d\" %surf_ind)\n",
    "    ind_mask = [True, True, True]\n",
    "    ind_mask[surf_ind] = False #  the training dataset is flagged by False\n",
    "    train_x = surf_dat\n",
    "    train_y = surf_labels[surf_ind]\n",
    "#     print(ind_mask)\n",
    "    test_x = list(compress(surfaces, ind_mask)) # the rest splits, flagged by True, are kept for testing\n",
    "    test_y = list(compress(surf_labels,ind_mask))\n",
    "    \n",
    "    for pipe_ind,pipe in enumerate(pipe_list):\n",
    "        print(\"Fitting classifier no. %d...\" %pipe_ind)\n",
    "        pipe.fit(train_x,train_y) # fit the pipeline for every train set and every clf\n",
    "        print (\"...done fitting\")\n",
    "        feat = list(pipe.named_steps['feature_selection'].get_support(indices = True))\n",
    "#         print(feat[:20])\n",
    "        feat_mask+=feat\n",
    "#         print(\"done getting features\")\n",
    "#         print(get_feat_occ(feat))\n",
    "#         print(\"lets print those fuckers\")\n",
    "#         get_feat_id(feat[:20], printit=1)\n",
    "        \n",
    "        for test_ind, test_d in enumerate(test_x):\n",
    "            y_pred = pipe.predict(test_d)\n",
    "            y_true = test_y[test_ind]\n",
    "            cm = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print (\"=============================================================\")\n",
    "            print(\"Trained on %d, testing on %d with %0.4s\" %(surf_ind, ind_mask.index(\"True\") pipe.named_steps['classifier']))\n",
    "            print(\"Prediction accuracy %f\" %pipe.score(test_d,y_true))\n",
    "            print(cm)\n",
    "            print(classification_report(y_pred=y_pred, y_true = y_true))        \n",
    "            print (\"=============================================================\")\n",
    "    \n",
    "tot_occs = get_feat_occ(feat_mask)\n",
    "# ids = get_feat_id(tot_occs[:20],printit=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1404, 'acrol0347', 'Golz', 'Time', 'Norm')\n",
      "(1405, 'acrol0348', 'Golz', 'Time', 'Norm')\n",
      "(1406, 'acrol0349', 'Golz', 'Time', 'Norm')\n",
      "(1442, 'acrol0385', 'Golz', 'Time', 'Norm')\n",
      "(1473, 'acrol0416', 'Golz', 'Time', 'Norm')\n",
      "(1482, 'acrol0425', 'Golz', 'Time', 'Norm')\n",
      "(1483, 'acrol0426', 'Golz', 'Time', 'Norm')\n",
      "(1487, 'acrol0430', 'Golz', 'Time', 'Norm')\n",
      "(1490, 'acrol0433', 'Golz', 'Time', 'Norm')\n",
      "(1496, 'acrol0439', 'Golz', 'Time', 'Norm')\n",
      "(1497, 'acrol0440', 'Golz', 'Time', 'Norm')\n",
      "(1498, 'acrol0441', 'Golz', 'Time', 'Norm')\n",
      "(1499, 'acrol0442', 'Golz', 'Time', 'Norm')\n",
      "(1500, 'acrol0443', 'Golz', 'Time', 'Norm')\n",
      "(1507, 'acrol0450', 'Golz', 'Time', 'Norm')\n",
      "(1508, 'acrol0451', 'Golz', 'Time', 'Norm')\n",
      "(1511, 'acrol0454', 'Golz', 'Time', 'Norm')\n",
      "(1513, 'acrol0456', 'Golz', 'Time', 'Norm')\n",
      "(1515, 'acrol0458', 'Golz', 'Time', 'Norm')\n",
      "(1517, 'acrol0460', 'Golz', 'Time', 'Norm')\n",
      "(1518, 'acrol0461', 'Golz', 'Time', 'Norm')\n",
      "(1519, 'acrol0462', 'Golz', 'Time', 'Norm')\n",
      "(1520, 'acrol0463', 'Golz', 'Time', 'Norm')\n",
      "(1521, 'acrol0464', 'Golz', 'Time', 'Norm')\n",
      "(1522, 'acrol0465', 'Golz', 'Time', 'Norm')\n",
      "(1523, 'acrol0466', 'Golz', 'Time', 'Norm')\n",
      "(1524, 'acrol0467', 'Golz', 'Time', 'Norm')\n",
      "(1525, 'acrol0468', 'Golz', 'Time', 'Norm')\n",
      "(1526, 'acrol0469', 'Golz', 'Time', 'Norm')\n",
      "(1528, 'acrol0471', 'Golz', 'Time', 'Norm')\n",
      "(1532, 'acrol0475', 'Golz', 'Time', 'Norm')\n",
      "(1533, 'acrol0476', 'Golz', 'Time', 'Norm')\n",
      "(1535, 'acrol0478', 'Golz', 'Time', 'Norm')\n",
      "(1537, 'acrol0480', 'Golz', 'Time', 'Norm')\n",
      "(1538, 'acrol0481', 'Golz', 'Time', 'Norm')\n",
      "(1539, 'acrol0482', 'Golz', 'Time', 'Norm')\n",
      "(1541, 'acrol0484', 'Golz', 'Time', 'Norm')\n",
      "(1542, 'acrol0485', 'Golz', 'Time', 'Norm')\n",
      "(1543, 'acrol0486', 'Golz', 'Time', 'Norm')\n",
      "(1544, 'acrol0487', 'Golz', 'Time', 'Norm')\n",
      "(1545, 'acrol0488', 'Golz', 'Time', 'Norm')\n",
      "(1573, 'acrol0516', 'Golz', 'Time', 'Norm')\n",
      "(1575, 'acrol0518', 'Golz', 'Time', 'Norm')\n",
      "(1579, 'acrol0522', 'Golz', 'Time', 'Norm')\n",
      "(1589, 'acrol0532', 'Golz', 'Time', 'Norm')\n",
      "(1600, 'acrol0543', 'Golz', 'Time', 'Norm')\n",
      "(1601, 'acrol0544', 'Golz', 'Time', 'Norm')\n",
      "(1614, 'acrol0557', 'Golz', 'Time', 'Norm')\n",
      "(1622, 'acrol0565', 'Golz', 'Time', 'Norm')\n",
      "(1624, 'acrol0567', 'Golz', 'Time', 'Norm')\n",
      "(1626, 'acrol0569', 'Golz', 'Time', 'Norm')\n",
      "(1628, 'acrol0571', 'Golz', 'Time', 'Norm')\n",
      "(1631, 'acrol0574', 'Golz', 'Time', 'Norm')\n",
      "(1635, 'acrol0578', 'Golz', 'Time', 'Norm')\n",
      "(1638, 'acrol0581', 'Golz', 'Time', 'Norm')\n",
      "(1640, 'acrol0583', 'Golz', 'Time', 'Norm')\n",
      "(1643, 'acrol0586', 'Golz', 'Time', 'Norm')\n",
      "(1647, 'acrol0590', 'Golz', 'Time', 'Norm')\n",
      "(1648, 'acrol0591', 'Golz', 'Time', 'Norm')\n",
      "(1649, 'acrol0592', 'Golz', 'Time', 'Norm')\n",
      "(1651, 'acrol0594', 'Golz', 'Time', 'Norm')\n",
      "(1653, 'acrol0596', 'Golz', 'Time', 'Norm')\n",
      "(1657, 'acrol0600', 'Golz', 'Time', 'Norm')\n",
      "(1658, 'acrol0601', 'Golz', 'Time', 'Norm')\n",
      "(1662, 'acrol0605', 'Golz', 'Time', 'Norm')\n",
      "(1663, 'acrol0606', 'Golz', 'Time', 'Norm')\n",
      "(1664, 'acrol0607', 'Golz', 'Time', 'Norm')\n",
      "(1669, 'acrol0612', 'Golz', 'Time', 'Norm')\n",
      "(1670, 'acrol0613', 'Golz', 'Time', 'Norm')\n",
      "(1671, 'acrol0614', 'Golz', 'Time', 'Norm')\n",
      "(1674, 'acrol0617', 'Golz', 'Time', 'Norm')\n",
      "(1690, 'acrol0633', 'Golz', 'Time', 'Norm')\n",
      "(1691, 'acrol0634', 'Golz', 'Time', 'Norm')\n",
      "(1692, 'acrol0635', 'Golz', 'Time', 'Norm')\n",
      "(1693, 'acrol0636', 'Golz', 'Time', 'Norm')\n",
      "(1694, 'acrol0637', 'Golz', 'Time', 'Norm')\n",
      "(1695, 'acrol0638', 'Golz', 'Time', 'Norm')\n",
      "(1696, 'acrol0639', 'Golz', 'Time', 'Norm')\n",
      "(1697, 'acrol0640', 'Golz', 'Time', 'Norm')\n",
      "(1698, 'acrol0641', 'Golz', 'Time', 'Norm')\n",
      "(1700, 'acrol0643', 'Golz', 'Time', 'Norm')\n",
      "(1703, 'acrol0646', 'Golz', 'Time', 'Norm')\n",
      "(1705, 'acrol0648', 'Golz', 'Time', 'Norm')\n",
      "(1724, 'acrol0667', 'Golz', 'Time', 'Norm')\n",
      "(1726, 'acrol0669', 'Golz', 'Time', 'Norm')\n",
      "(1729, 'acrol0672', 'Golz', 'Time', 'Norm')\n",
      "(1730, 'acrol0673', 'Golz', 'Time', 'Norm')\n",
      "(1734, 'acrol0677', 'Golz', 'Time', 'Norm')\n",
      "(1736, 'acrol0679', 'Golz', 'Time', 'Norm')\n",
      "(1743, 'acrol0686', 'Golz', 'Time', 'Norm')\n",
      "(1745, 'acrol0688', 'Golz', 'Time', 'Norm')\n",
      "(1747, 'acrol0690', 'Golz', 'Time', 'Norm')\n",
      "(1749, 'acrol0692', 'Golz', 'Time', 'Norm')\n",
      "(1751, 'acrol0694', 'Golz', 'Time', 'Norm')\n",
      "(1758, 'acrol0701', 'Golz', 'Time', 'Norm')\n",
      "(1778, 'acrol0721', 'Golz', 'Time', 'Norm')\n",
      "(1779, 'acrol0722', 'Golz', 'Time', 'Norm')\n",
      "(1780, 'acrol0723', 'Golz', 'Time', 'Norm')\n",
      "(1781, 'acrol0724', 'Golz', 'Time', 'Norm')\n",
      "(1784, 'acrol0727', 'Golz', 'Time', 'Norm')\n",
      "(1786, 'acrol0729', 'Golz', 'Time', 'Norm')\n",
      "(1789, 'acrol0732', 'Golz', 'Time', 'Norm')\n",
      "(1790, 'acrol0733', 'Golz', 'Time', 'Norm')\n",
      "(1792, 'acrol0735', 'Golz', 'Time', 'Norm')\n",
      "(1800, 'acrol0743', 'Golz', 'Time', 'Norm')\n",
      "(1802, 'acrol0745', 'Golz', 'Time', 'Norm')\n",
      "(1807, 'acrol0750', 'Golz', 'Time', 'Norm')\n",
      "(1808, 'acrol0751', 'Golz', 'Time', 'Norm')\n",
      "(1810, 'acrol0753', 'Golz', 'Time', 'Norm')\n",
      "(1811, 'acrol0754', 'Golz', 'Time', 'Norm')\n",
      "(1813, 'acrol0756', 'Golz', 'Time', 'Norm')\n",
      "(1814, 'acrol0757', 'Golz', 'Time', 'Norm')\n",
      "(1818, 'acrol0761', 'Golz', 'Time', 'Norm')\n",
      "(1822, 'acrol0765', 'Golz', 'Time', 'Norm')\n",
      "(1824, 'acrol0767', 'Golz', 'Time', 'Norm')\n",
      "(1827, 'acrol0770', 'Golz', 'Time', 'Norm')\n",
      "(1828, 'acrol0771', 'Golz', 'Time', 'Norm')\n",
      "(1829, 'acrol0772', 'Golz', 'Time', 'Norm')\n",
      "(1831, 'acrol0774', 'Golz', 'Time', 'Norm')\n",
      "(1834, 'acrol0777', 'Golz', 'Time', 'Norm')\n",
      "(1835, 'acrol0778', 'Golz', 'Time', 'Norm')\n",
      "(1836, 'acrol0779', 'Golz', 'Time', 'Norm')\n",
      "(1837, 'acrol0780', 'Golz', 'Time', 'Norm')\n",
      "(1838, 'acrol0781', 'Golz', 'Time', 'Norm')\n",
      "(1843, 'acrol0786', 'Golz', 'Time', 'Norm')\n",
      "(1889, 'acrol0832', 'Golz', 'Time', 'Norm')\n",
      "(1896, 'acrol0839', 'Golz', 'Time', 'Norm')\n",
      "(1899, 'acrol0842', 'Golz', 'Time', 'Norm')\n",
      "(1902, 'acrol0845', 'Golz', 'Time', 'Norm')\n",
      "(1906, 'acrol0849', 'Golz', 'Time', 'Norm')\n",
      "(1907, 'acrol0850', 'Golz', 'Time', 'Norm')\n",
      "(1908, 'acrol0851', 'Golz', 'Time', 'Norm')\n",
      "(1909, 'acrol0852', 'Golz', 'Time', 'Norm')\n",
      "(1912, 'acrol0855', 'Golz', 'Time', 'Norm')\n",
      "(1913, 'acrol0856', 'Golz', 'Time', 'Norm')\n",
      "(1923, 'acrol0866', 'Golz', 'Time', 'Norm')\n",
      "(1929, 'acrol0872', 'Golz', 'Time', 'Norm')\n",
      "(1934, 'acrol0877', 'Golz', 'Time', 'Norm')\n",
      "(1936, 'acrol0879', 'Golz', 'Time', 'Norm')\n",
      "(1942, 'acrol0885', 'Golz', 'Time', 'Norm')\n",
      "(1943, 'acrol0886', 'Golz', 'Time', 'Norm')\n",
      "(1945, 'acrol0888', 'Golz', 'Time', 'Norm')\n",
      "(1946, 'acrol0889', 'Golz', 'Time', 'Norm')\n",
      "(1947, 'acrol0890', 'Golz', 'Time', 'Norm')\n",
      "(1948, 'acrol0891', 'Golz', 'Time', 'Norm')\n",
      "(1949, 'acrol0892', 'Golz', 'Time', 'Norm')\n",
      "(1950, 'acrol0893', 'Golz', 'Time', 'Norm')\n",
      "(1951, 'acrol0894', 'Golz', 'Time', 'Norm')\n",
      "(1952, 'acrol0895', 'Golz', 'Time', 'Norm')\n",
      "(1953, 'acrol0896', 'Golz', 'Time', 'Norm')\n",
      "(1954, 'acrol0897', 'Golz', 'Time', 'Norm')\n",
      "(1955, 'acrol0898', 'Golz', 'Time', 'Norm')\n",
      "(1961, 'acrol0904', 'Golz', 'Time', 'Norm')\n",
      "(1962, 'acrol0905', 'Golz', 'Time', 'Norm')\n",
      "(1965, 'acrol0908', 'Golz', 'Time', 'Norm')\n",
      "(1970, 'acrol0913', 'Golz', 'Time', 'Norm')\n",
      "(1971, 'acrol0914', 'Golz', 'Time', 'Norm')\n",
      "(1972, 'acrol0915', 'Golz', 'Time', 'Norm')\n",
      "(1979, 'acrol0922', 'Golz', 'Time', 'Norm')\n",
      "(1981, 'acrol0924', 'Golz', 'Time', 'Norm')\n",
      "(1982, 'acrol0925', 'Golz', 'Time', 'Norm')\n",
      "(1985, 'acrol0928', 'Golz', 'Time', 'Norm')\n",
      "(1994, 'acrol0937', 'Golz', 'Time', 'Norm')\n",
      "(1995, 'acrol0938', 'Golz', 'Time', 'Norm')\n",
      "(1996, 'acrol0939', 'Golz', 'Time', 'Norm')\n",
      "(1997, 'acrol0940', 'Golz', 'Time', 'Norm')\n",
      "(2001, 'acrol0944', 'Golz', 'Time', 'Norm')\n",
      "(2031, 'acrol0974', 'Golz', 'Time', 'Norm')\n",
      "(2037, 'acrol0980', 'Golz', 'Time', 'Norm')\n",
      "(2038, 'acrol0981', 'Golz', 'Time', 'Norm')\n",
      "(2039, 'acrol0982', 'Golz', 'Time', 'Norm')\n",
      "(2040, 'acrol0983', 'Golz', 'Time', 'Norm')\n",
      "(2042, 'acrol0985', 'Golz', 'Time', 'Norm')\n",
      "(0, 'intsgnl', 'Phin', 'Time', 'Norm')\n",
      "(1, 'meanabs', 'Phin', 'Time', 'Norm')\n",
      "(3, 'ssi', 'Phin', 'Time', 'Norm')\n",
      "(4, 'var', 'Phin', 'Time', 'Norm')\n",
      "(5, 'rms', 'Phin', 'Time', 'Norm')\n",
      "(6, 'rng', 'Phin', 'Time', 'Norm')\n",
      "(17, 'mnf', 'Phin', 'Freq', 'Norm')\n",
      "(19, 'mmnf', 'Phin', 'Freq', 'Norm')\n",
      "(20, 'mmdf', 'Phin', 'Freq', 'Norm')\n",
      "(21, 'reFFT000', 'Phin', 'Freq', 'Norm')\n",
      "(22, 'reFFT001', 'Phin', 'Freq', 'Norm')\n",
      "(23, 'reFFT002', 'Phin', 'Freq', 'Norm')\n",
      "(24, 'reFFT003', 'Phin', 'Freq', 'Norm')\n",
      "(25, 'reFFT004', 'Phin', 'Freq', 'Norm')\n",
      "(26, 'reFFT005', 'Phin', 'Freq', 'Norm')\n",
      "(27, 'reFFT006', 'Phin', 'Freq', 'Norm')\n",
      "(28, 'reFFT007', 'Phin', 'Freq', 'Norm')\n",
      "(29, 'reFFT008', 'Phin', 'Freq', 'Norm')\n",
      "(30, 'reFFT009', 'Phin', 'Freq', 'Norm')\n",
      "(31, 'reFFT010', 'Phin', 'Freq', 'Norm')\n",
      "(32, 'reFFT011', 'Phin', 'Freq', 'Norm')\n",
      "(33, 'reFFT012', 'Phin', 'Freq', 'Norm')\n",
      "(35, 'reFFT014', 'Phin', 'Freq', 'Norm')\n",
      "(2092, 'amFFT011', 'Golz', 'Freq', 'Norm')\n",
      "(2093, 'amFFT012', 'Golz', 'Freq', 'Norm')\n",
      "(2094, 'amFFT013', 'Golz', 'Freq', 'Norm')\n",
      "(2095, 'amFFT014', 'Golz', 'Freq', 'Norm')\n",
      "(2096, 'amFFT015', 'Golz', 'Freq', 'Norm')\n",
      "(2097, 'amFFT016', 'Golz', 'Freq', 'Norm')\n",
      "(2098, 'amFFT017', 'Golz', 'Freq', 'Norm')\n",
      "(2102, 'amFFT021', 'Golz', 'Freq', 'Norm')\n",
      "(2103, 'amFFT022', 'Golz', 'Freq', 'Norm')\n",
      "(2104, 'amFFT023', 'Golz', 'Freq', 'Norm')\n",
      "(2596, 'phFFT002', 'Golz', 'Freq', 'Norm')\n",
      "(2081, 'amFFT000', 'Golz', 'Freq', 'Norm')\n",
      "(2083, 'amFFT002', 'Golz', 'Freq', 'Norm')\n",
      "(2085, 'amFFT004', 'Golz', 'Freq', 'Norm')\n",
      "(2086, 'amFFT005', 'Golz', 'Freq', 'Norm')\n",
      "(2087, 'amFFT006', 'Golz', 'Freq', 'Norm')\n",
      "(2088, 'amFFT007', 'Golz', 'Freq', 'Norm')\n",
      "(2089, 'amFFT008', 'Golz', 'Freq', 'Norm')\n",
      "(2090, 'amFFT009', 'Golz', 'Freq', 'Norm')\n",
      "(2091, 'amFFT010', 'Golz', 'Freq', 'Norm')\n",
      "(2600, 'phFFT006', 'Golz', 'Freq', 'Norm')\n",
      "(2602, 'phFFT008', 'Golz', 'Freq', 'Norm')\n",
      "(2604, 'phFFT010', 'Golz', 'Freq', 'Norm')\n",
      "(2605, 'phFFT011', 'Golz', 'Freq', 'Norm')\n",
      "(2609, 'phFFT015', 'Golz', 'Freq', 'Norm')\n",
      "(536, 'imFFT002', 'Phin', 'Freq', 'Norm')\n",
      "(537, 'imFFT003', 'Phin', 'Freq', 'Norm')\n",
      "(538, 'imFFT004', 'Phin', 'Freq', 'Norm')\n",
      "(541, 'imFFT007', 'Phin', 'Freq', 'Norm')\n",
      "(542, 'imFFT008', 'Phin', 'Freq', 'Norm')\n",
      "(543, 'imFFT009', 'Phin', 'Freq', 'Norm')\n",
      "(544, 'imFFT010', 'Phin', 'Freq', 'Norm')\n",
      "(545, 'imFFT011', 'Phin', 'Freq', 'Norm')\n",
      "(2594, 'phFFT000', 'Golz', 'Freq', 'Norm')\n",
      "(548, 'imFFT014', 'Phin', 'Freq', 'Norm')\n",
      "(2598, 'phFFT004', 'Golz', 'Freq', 'Norm')\n",
      "(2599, 'phFFT005', 'Golz', 'Freq', 'Norm')\n",
      "(552, 'imFFT018', 'Phin', 'Freq', 'Norm')\n",
      "(2601, 'phFFT007', 'Golz', 'Freq', 'Norm')\n",
      "(554, 'imFFT020', 'Phin', 'Freq', 'Norm')\n",
      "(2603, 'phFFT009', 'Golz', 'Freq', 'Norm')\n",
      "(2606, 'phFFT012', 'Golz', 'Freq', 'Norm')\n",
      "(2607, 'phFFT013', 'Golz', 'Freq', 'Norm')\n",
      "(2608, 'phFFT014', 'Golz', 'Freq', 'Norm')\n",
      "(2610, 'phFFT016', 'Golz', 'Freq', 'Norm')\n",
      "(2611, 'phFFT017', 'Golz', 'Freq', 'Norm')\n",
      "(2615, 'phFFT021', 'Golz', 'Freq', 'Norm')\n",
      "(2616, 'phFFT022', 'Golz', 'Freq', 'Norm')\n",
      "(2617, 'phFFT023', 'Golz', 'Freq', 'Norm')\n",
      "(1047, 'meanv', 'Golz', 'Time', 'Norm')\n",
      "(1048, 'stdr', 'Golz', 'Time', 'Norm')\n",
      "(1049, 'mx', 'Golz', 'Time', 'Norm')\n",
      "(1051, 'rngy', 'Golz', 'Time', 'Norm')\n",
      "(1053, 'hjorth', 'Golz', 'Time', 'Norm')\n",
      "(1055, 'se', 'Golz', 'Time', 'Norm')\n",
      "(1057, 'acrol0000', 'Golz', 'Time', 'Norm')\n",
      "(1058, 'acrol0001', 'Golz', 'Time', 'Norm')\n",
      "(1059, 'acrol0002', 'Golz', 'Time', 'Norm')\n",
      "(1060, 'acrol0003', 'Golz', 'Time', 'Norm')\n",
      "(1061, 'acrol0004', 'Golz', 'Time', 'Norm')\n",
      "(1062, 'acrol0005', 'Golz', 'Time', 'Norm')\n",
      "(1063, 'acrol0006', 'Golz', 'Time', 'Norm')\n",
      "(1064, 'acrol0007', 'Golz', 'Time', 'Norm')\n",
      "(1065, 'acrol0008', 'Golz', 'Time', 'Norm')\n",
      "(1066, 'acrol0009', 'Golz', 'Time', 'Norm')\n",
      "(1067, 'acrol0010', 'Golz', 'Time', 'Norm')\n",
      "(1068, 'acrol0011', 'Golz', 'Time', 'Norm')\n",
      "(1069, 'acrol0012', 'Golz', 'Time', 'Norm')\n",
      "(1070, 'acrol0013', 'Golz', 'Time', 'Norm')\n",
      "(1071, 'acrol0014', 'Golz', 'Time', 'Norm')\n",
      "(1072, 'acrol0015', 'Golz', 'Time', 'Norm')\n",
      "(1073, 'acrol0016', 'Golz', 'Time', 'Norm')\n",
      "(1074, 'acrol0017', 'Golz', 'Time', 'Norm')\n",
      "(1075, 'acrol0018', 'Golz', 'Time', 'Norm')\n",
      "(1076, 'acrol0019', 'Golz', 'Time', 'Norm')\n",
      "(1077, 'acrol0020', 'Golz', 'Time', 'Norm')\n",
      "(1078, 'acrol0021', 'Golz', 'Time', 'Norm')\n",
      "(1079, 'acrol0022', 'Golz', 'Time', 'Norm')\n",
      "(1080, 'acrol0023', 'Golz', 'Time', 'Norm')\n",
      "(1081, 'acrol0024', 'Golz', 'Time', 'Norm')\n",
      "(1082, 'acrol0025', 'Golz', 'Time', 'Norm')\n",
      "(1083, 'acrol0026', 'Golz', 'Time', 'Norm')\n",
      "(1084, 'acrol0027', 'Golz', 'Time', 'Norm')\n",
      "(1085, 'acrol0028', 'Golz', 'Time', 'Norm')\n",
      "(1086, 'acrol0029', 'Golz', 'Time', 'Norm')\n",
      "(1087, 'acrol0030', 'Golz', 'Time', 'Norm')\n",
      "(1088, 'acrol0031', 'Golz', 'Time', 'Norm')\n",
      "(1089, 'acrol0032', 'Golz', 'Time', 'Norm')\n",
      "(1090, 'acrol0033', 'Golz', 'Time', 'Norm')\n",
      "(1091, 'acrol0034', 'Golz', 'Time', 'Norm')\n",
      "(1092, 'acrol0035', 'Golz', 'Time', 'Norm')\n",
      "(1093, 'acrol0036', 'Golz', 'Time', 'Norm')\n",
      "(1094, 'acrol0037', 'Golz', 'Time', 'Norm')\n",
      "(1095, 'acrol0038', 'Golz', 'Time', 'Norm')\n",
      "(1096, 'acrol0039', 'Golz', 'Time', 'Norm')\n",
      "(1097, 'acrol0040', 'Golz', 'Time', 'Norm')\n",
      "(1098, 'acrol0041', 'Golz', 'Time', 'Norm')\n",
      "(1099, 'acrol0042', 'Golz', 'Time', 'Norm')\n",
      "(1100, 'acrol0043', 'Golz', 'Time', 'Norm')\n",
      "(1101, 'acrol0044', 'Golz', 'Time', 'Norm')\n",
      "(1102, 'acrol0045', 'Golz', 'Time', 'Norm')\n",
      "(1103, 'acrol0046', 'Golz', 'Time', 'Norm')\n",
      "(1104, 'acrol0047', 'Golz', 'Time', 'Norm')\n",
      "(1105, 'acrol0048', 'Golz', 'Time', 'Norm')\n",
      "(1106, 'acrol0049', 'Golz', 'Time', 'Norm')\n",
      "(1107, 'acrol0050', 'Golz', 'Time', 'Norm')\n",
      "(1108, 'acrol0051', 'Golz', 'Time', 'Norm')\n",
      "(1109, 'acrol0052', 'Golz', 'Time', 'Norm')\n",
      "(1110, 'acrol0053', 'Golz', 'Time', 'Norm')\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "# feats = [tot_occs[i] for i in range(40) ]\n",
    "# print(tot_occs)\n",
    "# print(tot_occs)\n",
    "# tot = dict(tot_occs)\n",
    "feat_list = []\n",
    "asd = OrderedDict(sorted(tot_occs.items(), key=lambda tot_occs: tot_occs[1]))\n",
    "for k,v in asd.items()[200:505]:\n",
    "    feat_list.append(k)\n",
    "nio = get_feat_id(feat_list,printit = 1)\n",
    "# print feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[439.91478874556327, 623.21723828234553, 833.93077225598097]\n"
     ]
    }
   ],
   "source": [
    "surfaces = np.split(data_X,3)\n",
    "print([surfaces[i][1,0] for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = 42\n",
    "skipdata = 20\n",
    "best_parameters = np.zeros((X.shape[0],len(tmpind),len(classifiers))).tolist()\n",
    "best_clf = np.zeros((X.shape[0],len(tmpind),len(classifiers))).tolist()\n",
    "best_fs_sc = np.zeros((X.shape[0],len(tmpind),len(classifiers))).tolist()\n",
    "masks = []\n",
    "for i in range(X.shape[0]):\n",
    "    y_tot = np.copy(Ysp[i]) ; y_tot = y_tot[::skipdata]\n",
    "    for j in range(len(tmpind)):\n",
    "        x_tot = np.copy(Xsp[i][j]) ; x_tot = x_tot[::skipdata,:]\n",
    "#         print(x_tot.shape)\n",
    "        fs = SelectKBest(k=100)\n",
    "        fs.fit(x_tot,y_tot)\n",
    "        mask = list(fs.get_support(indices = True))\n",
    "        masks+=mask\n",
    "#         print masks\n",
    "occs = get_feat_occ(masks)\n",
    "print(occs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[(8902, 3107), (8902, 3107), (8902, 6214), (8898, 3107), (8898, 3107), (8898, 6214)]\n",
      "[(8902, 3107), (8902, 3107), (8902, 6214), (8902, 3107), (8902, 3107), (8902, 6214), (8898, 3107), (8898, 3107), (8898, 6214)]\n"
     ]
    }
   ],
   "source": [
    "ind_list = [1,0,1]\n",
    "bool_ind = [bool(ind_list[i]) for i in range(len(ind_list))]\n",
    "bool_result = X[bool_ind]\n",
    "print (len(X),len(bool_result))\n",
    "print([ bool_result[i][j].shape for i in range(len(bool_result)) for j in range(len(bool_result[i]))])\n",
    "print([ X[i][j].shape for i in range(len(X)) for j in range(len(X[i]))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
