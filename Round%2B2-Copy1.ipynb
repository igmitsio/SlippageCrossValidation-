{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "from copy import deepcopy, copy\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import shutil\n",
    "import os\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "# from featext2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "#matplotlib qt\n",
    "# inline (suitable for ipython only, shown inside browser!) or qt (suitable in general, shown in external window!)\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.mplot3d import Axes3D #, axes3d\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, ParameterGrid, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.decomposition import PCA, KernelPCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LassoCV, RandomizedLasso\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2, f_classif, mutual_info_classif, SelectFdr\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import datetime\n",
    "import urllib\n",
    "import tarfile\n",
    "# import joblib\n",
    "# from joblib import Parallel, delayed, Memory\n",
    "from tempfile import mkdtemp\n",
    "import copy_reg\n",
    "import types\n",
    "import itertools\n",
    "from itertools import compress\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#import multiprocessing\n",
    "def _pickle_method(m):\n",
    "    if m.im_self is None:\n",
    "        return getattr, (m.im_class, m.im_func.func_name)\n",
    "    else:\n",
    "        return getattr, (m.im_self, m.im_func.func_name)\n",
    "copy_reg.pickle(types.MethodType, _pickle_method)\n",
    "\n",
    "\n",
    "h = .2  # step size in the mesh\n",
    "# names = [\"NearNb\", \"RBFSVM1\", \"NaiveBayes\", \"MLP1\", \"Log.Regr\", \"RandFor\", \"AdaBoost\", \"EnsembleMLP\"]\n",
    "# classifiers = [\n",
    "#     KNeighborsClassifier(5),\n",
    "#     SVC(gamma='auto', C=1),\n",
    "#     MLPClassifier(solver='lbfgs',alpha=1e-4,hidden_layer_sizes=(10,10),random_state=1,verbose=True),\n",
    "#     RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "# ]\n",
    "\n",
    "# cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "# parameters_clf = [{'n_neighbors':range(3,10)},\n",
    "#               {'kernel':['rbf'], 'C':[0.01,0.1,1,10,100,1000]},\n",
    "#               {'solver':['lbfgs'], 'alpha':[1e-5,1e-2], 'hidden_layer_sizes':[(10,10),(50,50),(100,100)]},\n",
    "#               {'max_depth':[4,7,10,20],'n_estimators':[5,10,20],'max_features':[20,35,50]},\n",
    "#               {'solver':['lbfgs'], 'alpha':[1e-5], 'hidden_layer_sizes':[(len(names)-1,len(names)-1),(len(names)-1,2)]}\n",
    "#              ]\n",
    "# makepipe_parameters_clf = [{'classifier__'+key:p[key] for key in p} for p in parameters_clf]\n",
    "# makepipe_parameters_clf += [{'feature_selection__k': (750,500,100), 'feature_selection__score_func': [mutual_info_classif]},\n",
    "#                             {'decomp__n_components': (100,50)}]\n",
    "# metric = ['accuracy','f1']\n",
    "# dataset = 0 # all datasets (0), dataset 1-2 (1), dataset 3 (2), dataset4 (3)\n",
    "# download = 1 # Download pre-computed (1) data or compute them anew (0)\n",
    "window = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Feature Names ############\n",
    "\"\"\"features:                                                                       ||      if       \n",
    "   |--> time domain      :                                                         || samples = 1024\n",
    "   |----|---> phinyomark : 11+3{shist} --------------------------> = 14+0.0samples ||             14\n",
    "   |----|---> golz       : 10+samples{acrol} --------------------> = 10+1.0samples ||           1034\n",
    "   |--> frequency domain :                                                                          \n",
    "   |----|---> phinyomark : 3{arco}+4{mf}+2(samples/2+1){RF,IF} --> =  9+1.0samples ||           1033\n",
    "   |----|---> golz       : 2(samples/2+1){AF,PF} ----------------> =  2+1.0samples ||           1026\n",
    "   |----|----------------|-------alltogether---------------------> = 35+3.0samples || numfeat = 3107\n",
    "\"\"\"\n",
    "## Time Domain Phinyomark feats\n",
    "featnames = ['intsgnl', 'meanabs', 'meanabsslp', 'ssi', 'var', 'rms', 'rng', 'wavl', 'zerox', 'ssc', 'wamp', \n",
    "             'shist1', 'shist2', 'shist3']                                                   # 11+3{shist}\n",
    "## Frequency Domain Phinyomark feats\n",
    "featnames += ['arco1', 'arco2', 'arco3', 'mnf', 'mdf', 'mmnf', 'mmdf']                       # 3{arco}+4{mf}\n",
    "featnames += ['reFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{RF}\n",
    "featnames += ['imFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{IF}\n",
    "## Time Domain Golz feats\n",
    "featnames += ['meanv', 'stdr', 'mx', 'rngx', 'rngy', 'med', 'hjorth', 'sentr', 'se', 'ssk']  # 10\n",
    "featnames += ['acrol{:04d}'.format(i) for i in range(window)]                                # samples{acrol}\n",
    "## Frequency Domain Golz feats\n",
    "featnames += ['amFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{AF}\n",
    "featnames += ['phFFT{:03d}'.format(i) for i in range(window/2+1)]                            # samples/2+1{PF}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Prepare the indeces for each feature ############\n",
    "def get_feat_id(feat_ind, printit=0, sample_window=window): \n",
    "    \"\"\"Find the corresponding indeces of the desired features inside feature vector,\n",
    "    and link them with their names and level of abstraction\n",
    "    -> feat_ind        : range of indeces\n",
    "    -> printit         : print output indeces (1) or not (0)\n",
    "    -> sample_window   : parameter for accurate computation of feature indeces\n",
    "    <- full_path_id    : indeces of all features\n",
    "    <- norm_time_feats : indeces of time features\n",
    "    <- norm_freq_feats : indeces of frequency features\n",
    "    \"\"\"\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "    norm_time_phin = range(0,14)\n",
    "    norm_freq_phin = range(norm_time_phin[-1] + 1, norm_time_phin[-1] + 9 + sample_window + 1)\n",
    "    norm_time_golz = range(norm_freq_phin[-1] + 1, norm_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    norm_freq_golz = range(norm_time_golz[-1] + 1, norm_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    norm_time_feats = norm_time_phin + norm_time_golz\n",
    "    norm_freq_feats = norm_freq_phin + norm_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    norm_feats = norm_time_feats + norm_freq_feats\n",
    "\n",
    "    # get the feat inds wrt their source : 3rd level\n",
    "    disp = norm_feats[-1]+1\n",
    "    ftfn_time_phin = range(disp ,disp + 14)\n",
    "    ftfn_freq_phin = range(ftfn_time_phin[-1] + 1, ftfn_time_phin[-1] + 9 + sample_window + 1)\n",
    "    ftfn_time_golz = range(ftfn_freq_phin[-1] + 1, ftfn_freq_phin[-1] + 10 + sample_window + 1)\n",
    "    ftfn_freq_golz = range(ftfn_time_golz[-1] + 1, ftfn_time_golz[-1] + 2 + sample_window + 1)\n",
    "    # get the feat inds wrt their domain : 2nd level \n",
    "    ftfn_time_feats = ftfn_time_phin + ftfn_time_golz\n",
    "    ftfn_freq_feats = ftfn_freq_phin + ftfn_freq_golz\n",
    "    # get the feat inds wrt their prefeat: 1st level \n",
    "    ftfn_feats = ftfn_time_feats + ftfn_freq_feats\n",
    "\n",
    "    # create the final \"reference dictionary\"\n",
    "    # 3 np.arrays, id_list[0] = level 1 etc\n",
    "    id_list = [np.zeros((len(ftfn_feats + norm_feats),1)) for i in range(3)]\n",
    "    id_list[0][:norm_feats[-1]+1] = 0 # 0 signifies norm / 1 signifies ft/fn\n",
    "    id_list[0][norm_feats[-1]+1:] = 1\n",
    "\n",
    "    id_list[1][:norm_time_phin[-1]+1] = 0 # 0 signifies time / 1 signifies freq\n",
    "    id_list[1][norm_time_phin[-1]+1:norm_freq_phin[-1]+1] = 1\n",
    "    id_list[1][norm_freq_phin[-1]+1:norm_time_golz[-1]+1] = 0\n",
    "    id_list[1][norm_time_golz[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[1][norm_freq_golz[-1]+1:ftfn_time_phin[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_phin[-1]+1:ftfn_freq_phin[-1]+1] = 1\n",
    "    id_list[1][ftfn_freq_phin[-1]+1:ftfn_time_golz[-1]+1] = 0\n",
    "    id_list[1][ftfn_time_golz[-1]+1:] = 1\n",
    "\n",
    "    id_list[2][:norm_freq_phin[-1]+1] = 0 #0 signifies phinyomark / 1 signifies golz\n",
    "    id_list[2][norm_freq_phin[-1]+1:norm_freq_golz[-1]+1] = 1\n",
    "    id_list[2][norm_freq_golz[-1]+1:ftfn_freq_phin[-1]+1] = 0\n",
    "    id_list[2][ftfn_freq_phin[-1]+1:] = 1 \n",
    "    \n",
    "    full_path_id = [np.zeros((len(feat_ind),5)) for i in range(len(feat_ind))]\n",
    "   \n",
    "    for ind, val in enumerate(feat_ind):\n",
    "        full_path_id[ind] = [val, id_list[2][val], id_list[1][val], id_list[0][val]]\n",
    "        if (printit==1):\n",
    "            if(full_path_id[ind][1]==0):\n",
    "                lvl3 = 'Phin'\n",
    "            else:\n",
    "                lvl3 = 'Golz'\n",
    "            if(full_path_id[ind][2]==0):\n",
    "                lvl2 = 'Time'\n",
    "            else:\n",
    "                lvl2 = 'Freq'\n",
    "            if(full_path_id[ind][3]==0):\n",
    "                lvl1 = 'Norm'\n",
    "            else:\n",
    "                lvl1 = 'Ft/Fn'\n",
    "            print(feat_ind[ind],featnames[val%(norm_feats[-1]+1)],lvl3,lvl2,lvl1)\n",
    "    \n",
    "    return(full_path_id,norm_time_feats,norm_freq_feats)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feat_occ(feat_masks):\n",
    "    #get the number of occurences for each feature after SelectKbest\n",
    "#     print(\"If it ain't working, just make sure you're adding the lists instead of concatenating them,\")\n",
    "#     print(\"if the input isn't a single list you'll get the unhashable error\")\n",
    "    feat_occ = Counter(feat_masks)\n",
    "    return feat_occ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tot_feats1(fs, subfs):\n",
    "    ###############################################################################################################\n",
    "    # Version 2, using the bool masks and keeping an array of 6x3000 feats \n",
    "    ###############################################################################################################\n",
    "    # If checking for FnormAll, you end up with 36 models of (trained_on, tested_on) combinations but TECHNICALLY\n",
    "    # the features are the same for every trained_on \"sixplet\" so there's no need to iterate over all the tested_on\n",
    "    # indeces. Therefore, ts = 2 is chosen arbitrarily \n",
    "    ts = 2;\n",
    "    folder = 'results1/'\n",
    "    \n",
    "    # the features kept for surface i will be stored in bool_tot_feats[i] (final size: 6x1000)\n",
    "    bool_tot_feats = []\n",
    "    \n",
    "    for tr in range(6):\n",
    "        # for every training surface     \n",
    "        model = 'fs_' + str(fs) + '_subfs_' + str(subfs) + '_tr_' + str(tr) + '_ts_' + str(ts) + '.npz'\n",
    "        datapath = 'data/' + folder + model\n",
    "        model_file = np.load(datapath)\n",
    "        model = model_file['model']\n",
    "\n",
    "        #keep a list of the 1000 features kept\n",
    "        bool_model_features = list(model[0].named_steps['feature_selection'].get_support(indices = False))\n",
    "    #     model_feat_scores = list(model[0].named_steps['feature_selection'].scores_)\n",
    "        bool_tot_feats.append(bool_model_features)\n",
    "\n",
    "    return bool_tot_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMPORT GLOB IS MANDATORY\n",
    "\"\"\"\n",
    "\n",
    "def get_tot_feats5(fs, subfs):\n",
    "    import glob\n",
    "     ###############################################################################################################\n",
    "    # Version 2, using the bool masks and keeping an array of 6x3000 feats \n",
    "    ###############################################################################################################\n",
    "    # If checking for FnormAll, you end up with 36 models of (trained_on, tested_on) combinations but TECHNICALLY\n",
    "    # the features are the same for every trained_on \"sixplet\" so there's no need to iterate over all the tested_on\n",
    "    # indeces. Therefore, ts = 2 is chosen arbitrarily \n",
    "    \n",
    "    filenames = glob.glob(\"data/results5/fs_\" + str(fs) + \"_subfs_\" + str(subfs) + \"_*_ts_0.npz\")\n",
    "    # the features kept for surface i will be stored in bool_tot_feats[i] (final size: 6x1000)\n",
    "    bool_tot_feats = []\n",
    "    \n",
    "    for filn in filenames:\n",
    "        # for every training surface     \n",
    "        model_file = np.load(filn)\n",
    "        model = model_file['model']\n",
    "\n",
    "        #keep a list of the 1000 features kept\n",
    "        bool_model_features = list(model[0].named_steps['feature_selection'].get_support(indices = False))\n",
    "    #     model_feat_scores = list(model[0].named_steps['feature_selection'].scores_)\n",
    "        bool_tot_feats.append(bool_model_features)\n",
    "\n",
    "    return bool_tot_feats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_common_feats(bool_tot_feats, skip_surf = 6, print_common_feats = 0):   \n",
    "    # skip_surf = 6 by default so you won't skip any surfaces.\n",
    "    # returns the list of inds for the common feats\n",
    "    trans_test_bools = []\n",
    "\n",
    "    for i in range(len(bool_tot_feats)):\n",
    "        if i != skip_surf:\n",
    "            trans_test_bools.append(bool_tot_feats[i])\n",
    "        else: \n",
    "            continue\n",
    "            \n",
    "    trans_test_bools = np.transpose(trans_test_bools)\n",
    "    common_feats = []\n",
    "    matches  =[]\n",
    "    for i in range(len(trans_test_bools)):\n",
    "        matches.append(np.all(trans_test_bools[i]))\n",
    "    for ind, val in enumerate(matches):\n",
    "        if val:\n",
    "            common_feats.append(ind)\n",
    "    print(\"===============================================================\")       \n",
    "    print(\"%d common feats, out of %d total\" %(len(common_feats),len(matches)))\n",
    "    full_names, _, _ = get_feat_id(common_feats, printit = print_common_feats)\n",
    "    freq_counter, time_counter = freq_time_counter(full_names)\n",
    "    print(\"of which, %d (%.2f%%) were Freq features and %d (%.2f%%) were Time features\" %(freq_counter, (float(freq_counter)/len(common_feats))*100, time_counter, (float(time_counter)/len(common_feats))*100 ))\n",
    "\n",
    "    print(\"===============================================================\")\n",
    "    \n",
    "    return common_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freq_time_counter(full_names):\n",
    "    f_c = 0; t_c = 0\n",
    "    for i in range(len(full_names)):\n",
    "        if full_names[i][2] == 1:\n",
    "            f_c += 1\n",
    "        else: \n",
    "            t_c += 1\n",
    "    return (f_c, t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================\n",
      "317 common feats, out of 3107 total\n",
      "of which, 44 (13.88%) were Freq features and 273 (86.12%) were Time features\n",
      "===============================================================\n"
     ]
    }
   ],
   "source": [
    "### Example \n",
    "\n",
    "tot_feats = get_tot_feats1(fs = 0, subfs = 3)\n",
    "common_feats = get_common_feats(bool_tot_feats = tot_feats, skip_surf = 2, print_common_feats= 0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
