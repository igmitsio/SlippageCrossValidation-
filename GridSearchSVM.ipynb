{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ATTENTION SUMMONER, KANOUME SCALE KAI TA OUTER_TRAINING_DATA H OXI GAMW TO KERATO MOU TO TRAGIO? KI AN NAI,\n",
    "### TO LOGIKO FAINETAI NA EINAI NA TO KANOUME ME DIKO TOUS SCALER KI OXI ME TO INNER. EINAI OMWS LOGIKO???????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.semi_supervised import LabelSpreading, LabelPropagation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LassoCV, RandomizedLasso\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold #, GridSearchCV, cross_val_score\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D #, axes3d\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "import itertools\n",
    "\n",
    "\n",
    "import operator\n",
    "import winsound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gathered features:  (10063, 6216) (10063,) (10086, 6216) (10086,) (20149, 6216) (20149,) 9493.0\n"
     ]
    }
   ],
   "source": [
    "datapath = 'data/'\n",
    "XYfile = datapath + 'newfeatures_1024_1_10_10000_XY.npz'\n",
    "Xpcafile = datapath + 'newfeatures_1024_1_10_10000_dimred.npz'\n",
    "Xtestsds = datapath + 'newfeatures_1024_1_10_10000_testds.npz'\n",
    "############# GATHERING into one complete array\n",
    "#X = np.load(XYfile)['X']\n",
    "with np.load(XYfile, encoding = 'latin1') as inpf:\n",
    "    X = inpf['X']\n",
    "    Y = inpf['Y']\n",
    "# with np.load(Xpcafile, encoding = 'latin1') as inpf:\n",
    "#     X = inpf['Xpca']\n",
    "#     Y = inpf['Y']\n",
    "#Y = np.load(XYfile)['Y']\n",
    "# with np.load(Xtestsds, encoding = 'latin1') as inpf:\n",
    "#     X = inpf['ds']\n",
    "\n",
    "\n",
    "print ('gathered features: ', X[0].shape, Y[0].shape, X[1].shape, Y[1].shape, X[2].shape, Y[2].shape, np.sum(Y[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pipe(clf,sca,order):\n",
    "# order = 1 : first perform feature selection and then apply PCA\n",
    "# order = 0 : first apply PCA and then reduce the transformed features\n",
    "    if order:\n",
    "        pipeline = Pipeline([('scaler', sca),\n",
    "                    ('feature_selection', SelectKBest(mutual_info_classif)),\n",
    "                    ('decomp', PCA()),        \n",
    "                    ('classifier', clf) ])\n",
    "    else:\n",
    "        pipeline = Pipeline([('scaler', sca),\n",
    "                    ('decomp', PCA()),                 \n",
    "                    ('feature_selection', SelectKBest(mutual_info_classif)),        \n",
    "                    ('classifier', clf) ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "#     \"\"\"\n",
    "#     This function prints and plots the confusion matrix.\n",
    "#     Normalization can be applied by setting `normalize=True`.\n",
    "#     \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "   \n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"Normalized confusion matrix\")\n",
    "   \n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"sonar.csv\",header = None)\n",
    "dataset = df.values\n",
    "Xsonar = dataset[:, 0:60].astype(float)\n",
    "Ysonar = dataset[:,60]\n",
    "#change the string output to int \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Ysonar)\n",
    "ysonar = encoder.transform(Ysonar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copied \n",
    "window = 1024\n",
    "\n",
    "## Time Domain Phinyomark feats\n",
    "featnames = ['intsgnl', 'meanabs', 'meanabsslp', 'ssi', 'var', 'rms', 'rng', 'wavl', 'zerox', 'ssc', 'wamp', \n",
    "             'shist1', 'shist2', 'shist3']                                                   # 11+3{shist}\n",
    "## Frequency Domain Phinyomark feats\n",
    "featnames += ['arco1', 'arco2', 'arco3', 'mnf', 'mdf', 'mmnf', 'mmdf']                       # 3{arco}+4{mf}\n",
    "featnames += ['reFFT{:03d}'.format(i) for i in range(window//2+1)]                            # samples/2+1{RF}\n",
    "featnames += ['imFFT{:03d}'.format(i) for i in range(window//2+1)]                            # samples/2+1{IF}\n",
    "## Time Domain Golz feats\n",
    "featnames += ['meanv', 'stdr', 'mx', 'rngx', 'rngy', 'med', 'hjorth', 'sentr', 'se', 'ssk']  # 10\n",
    "featnames += ['acrol{:04d}'.format(i) for i in range(window)]                                # samples{acrol}\n",
    "## Frequency Domain Golz feats\n",
    "featnames += ['amFFT{:03d}'.format(i) for i in range(window//2+1)]                            # samples/2+1{AF}\n",
    "featnames += ['phFFT{:03d}'.format(i) for i in range(window//2+1)]                            # samples/2+1{PF}\n",
    "featnames += ['ffaf']                                                                        # 1{ffaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################## FEATURE SELECTION #########################################################\n",
    "# feature names\n",
    "\n",
    "shift =1 ; keepfromshift = 10; samplesperdataset = 10000\n",
    "\n",
    "tmpind = {}\n",
    "tmpind[2] = range(X[0].shape[1])\n",
    "tmpind[0] = range(X[0].shape[1]//2)\n",
    "tmpind[1] = range(X[0].shape[1]//2,X[0].shape[1])\n",
    "tmpind = np.array([i for _,i in tmpind.items()])\n",
    "\n",
    "featpath = datapath+'features/'+str(window)+'_'+str(shift)+'/'\n",
    "featname = 'newfeatures'+'_'+str(window)+'_'+str(shift)+'_'+str(keepfromshift)+'_'+str(samplesperdataset)\n",
    "\n",
    "\n",
    "\n",
    "numfeat = 10 # number of features to show\n",
    "nfeat = 1000 # number of features to keep\n",
    "#namesid = ['sf{:04d}'.format(i) if i<X[0].shape[1]/2 else 'ftn{:04d}'.format(i) for i in range(X[0].shape[1])]\n",
    "namesid = [['sf{:04d}'.format(i) for i in range(X[0].shape[1]//2)],\n",
    "           ['ftn{:04d}'.format(i) for i in range(X[0].shape[1]//2)],\n",
    "           ['sf{:04d}'.format(i) if i<X[0].shape[1]//2 else 'ftn{:04d}'.format(i%X[0].shape[1]//2) for i in range(X[0].shape[1])]]\n",
    "namesf = [['sf_{}'.format(featnames[i]) for i in range(X[0].shape[1]//2)],\n",
    "         ['ftn_{}'.format(featnames[i]) for i in range(X[0].shape[1]//2)],\n",
    "         ['sf_{}'.format(featnames[i]) if i<X[0].shape[1]//2 else 'ftn_{}'.format(featnames[i%X[0].shape[1]//2]) for i in range(X[0].shape[1])]]\n",
    "########## use RandomizedLasso of MutualInfo as the model to select features and find their importances ############\n",
    "featselfile = featpath+featname+'_featselall'+'.npz'\n",
    "tmpskip = [int(len(tmpind[i])/3000) for i in range(len(tmpind))]\n",
    "#tmpskip = [1 for i in range(3)]\n",
    "start_time = time.time()\n",
    "if os.path.isfile(featselfile):\n",
    "    print(\"hey yooooo\")\n",
    "    #rlasso = np.load(featselfile)['rlasso'].tolist()\n",
    "    featsel = np.load(featselfile)['featsel'].tolist()\n",
    "    print(\"Selected Features FOUND PRECOMPUTED! Loading DONE in: %s seconds \" % (time.time() - start_time))\n",
    "else:                                                                                                    \n",
    "    with warnings.catch_warnings():\n",
    "        print(\"You're in for a long ride\")\n",
    "        warnings.simplefilter('ignore', UserWarning)\n",
    "        warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "        featsel = [[SelectKBest(mutual_info_classif,'all').fit(X[i][:-1:tmpskip[i],tmpind[j]],Y[i][:-1:tmpskip[i]]) \n",
    "                    for j in range(3)] for i in range(3)]\n",
    "        print(\"Selected Features NOT FOUND PRECOMPUTED! Selection DONE in: %s seconds \" % (time.time() - start_time))\n",
    "        # loop for all datasets (12,3,all) and all features (sf,ftn,all)\n",
    "        #featsel = [[RandomizedLasso(fit_intercept=False,normalize=False).fit(X[i][:-1:tmpskip[i],tmpind[j]],Y[i][:-1:tmpskip[i]]) \n",
    "        #Parallel(n_jobs=-1)([delayed(feat) (p[k:k+window],*featparam) for k in range(0,len(p)-window,shift)])\n",
    "#         featsel = [Parallel(n_jobs=-1)([delayed(SelectKBest(mutual_info_classif,'all').fit) \n",
    "#                     (X[i][:-1:tmpskip[i],tmpind[j]],Y[i][:-1:tmpskip[i]])\n",
    "#                     for i,j in itertools.product(range(len(X)),range(3))])]\n",
    "#         featsel = np.array([[featsel[0][i*len(range(3))+j] for j in range(3)] for i in range(len(X))])\n",
    "#                    for j in range(3) for i in range(len(X))]\n",
    "        \n",
    "        #np.savez(featselfile,rlasso=np.array(rlasso))\n",
    "        np.savez(featselfile,featsel=featsel)\n",
    "# rank features\n",
    "# print \"----> Features sorted by their rank (std norm):\"\n",
    "bestix = {}\n",
    "wrstix = {}\n",
    "# for i in range(len(X)): # for all diff data sets\n",
    "# Im only using the first one so the for above doesnt apply\n",
    "for i in range (3):\n",
    "    bestix[i] = {}\n",
    "    wrstix[i] = {}\n",
    "    for j in range(3): # for all diff feature sets\n",
    "#         tmp = sorted(zip(map(lambda x: round(x,4), featsel[i][j].scores_),namesf[j]),reverse=True)\n",
    "        print(j)\n",
    "        bestix[i][j] = np.array(featsel[i][j].scores_).argsort()[:][::-1]\n",
    "        #wrstix[i][j] = np.array(featsel[i][j].scores_).argsort()[:nfeat][::1]\n",
    "        wrstix[i][j] = np.array(featsel[i][j].scores_).argsort()[:][::1]\n",
    "#         print 'Best '+str(numfeat)+': ',tmp[:numfeat], bestix[i][j].shape, bestix[i][j][:numfeat]\n",
    "#         print 'Worst '+str(numfeat)+': ',tmp[-numfeat:], wrstix[i][j].shape, wrstix[i][j][:numfeat]\n",
    "bestix = np.array([[ij for _,ij in i.items()] for _,i in bestix.items()])\n",
    "wrstix = np.array([[ij for _,ij in i.items()] for _,i in wrstix.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer loop 1/5\n",
      "Inner fold 1/5\n",
      "Inner fold 2/5\n",
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n",
      "Inner fold 1/5\n",
      "Inner fold 2/5\n",
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n",
      "Inner fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner fold 2/5\n",
      "Inner fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner fold 4/5\n",
      "Inner fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [ 0.73257576  0.74166667  0.71685606]\n",
      "Best 2 models for outer fold 0 are: \n",
      " \n",
      "model no.1 \n",
      "Inner score: 0.741667 VS Outer score: 0.814815 \n",
      "\n",
      "----------------------------------------------------------\n",
      "model no.0 \n",
      "Inner score: 0.732576 VS Outer score: 0.777778 \n",
      "\n",
      "----------------------------------------------------------\n",
      "Features selected: \n",
      "\n",
      "None\n",
      "[[    7.  1324.  1325.  1326.  1460.  1461.  1462.  1463.  1464.  1465.]\n",
      " [    7.  1324.  1325.  1326.  1460.  1461.  1462.  1463.  1464.  1465.]]\n",
      "Outer loop 2/5\n",
      "Inner fold 1/5\n",
      "Inner fold 2/5\n",
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n",
      "Inner fold 1/5\n",
      "Inner fold 2/5\n",
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n",
      "Inner fold 1/5\n",
      "Inner fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [ 0.69895833  0.76751894  0.70198864]\n",
      "Best 2 models for outer fold 1 are: \n",
      " \n",
      "model no.1 \n",
      "Inner score: 0.767519 VS Outer score: 0.851852 \n",
      "\n",
      "----------------------------------------------------------\n",
      "model no.2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner score: 0.701989 VS Outer score: 0.666667 \n",
      "\n",
      "----------------------------------------------------------\n",
      "Features selected: \n",
      "\n",
      "None\n",
      "[[    7.   535.   556.   573.   576.   590.   597.  3115.  3118.  4157.]\n",
      " [    7.   535.   556.   567.   573.   576.   590.   597.  3115.  4157.]]\n",
      "Outer loop 3/5\n",
      "Inner fold 1/5\n",
      "Inner fold 2/5\n",
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n",
      "Inner fold 1/5\n",
      "Inner fold 2/5\n",
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n",
      "Inner fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [ 0.70189394  0.77007576  0.67689394]\n",
      "Best 2 models for outer fold 2 are: \n",
      " \n",
      "model no.1 \n",
      "Inner score: 0.770076 VS Outer score: 0.802469 \n",
      "\n",
      "----------------------------------------------------------\n",
      "model no.0 \n",
      "Inner score: 0.701894 VS Outer score: 0.666667 \n",
      "\n",
      "----------------------------------------------------------\n",
      "Features selected: \n",
      "\n",
      "None\n",
      "[[ 2009.  3115.  4157.  4255.  4257.  4258.  4278.  4279.  4280.  4281.]\n",
      " [ 2009.  3115.  4157.  4255.  4257.  4258.  4278.  4279.  4280.  4281.]]\n",
      "Outer loop 4/5\n",
      "Inner fold 1/5\n",
      "Inner fold 2/5\n",
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n",
      "Inner fold 1/5\n",
      "Inner fold 2/5\n",
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n",
      "Inner fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner fold 2/5\n",
      "Inner fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [ 0.73920455  0.76410985  0.74214015]\n",
      "Best 2 models for outer fold 3 are: \n",
      " \n",
      "model no.1 \n",
      "Inner score: 0.764110 VS Outer score: 0.765432 \n",
      "\n",
      "----------------------------------------------------------\n",
      "model no.2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ifoundacarrot\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner score: 0.742140 VS Outer score: 0.703704 \n",
      "\n",
      "----------------------------------------------------------\n",
      "Features selected: \n",
      "\n",
      "None\n",
      "[[    7.  4157.  4305.  4310.  4320.  4322.  4403.  4405.  4410.  4411.]\n",
      " [    7.  4157.  4305.  4310.  4320.  4322.  4403.  4405.  4410.  4411.]]\n",
      "Outer loop 5/5\n",
      "Inner fold 1/5\n",
      "Inner fold 2/5\n",
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n",
      "Inner fold 1/5\n",
      "Inner fold 2/5\n",
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n",
      "Inner fold 1/5\n",
      "Inner fold 2/5\n",
      "Inner fold 3/5\n",
      "Inner fold 4/5\n",
      "Inner fold 5/5\n",
      "\n",
      " [ 0.59488636  0.72793561  0.60757576]\n",
      "Best 2 models for outer fold 4 are: \n",
      " \n",
      "model no.1 \n",
      "Inner score: 0.727936 VS Outer score: 0.759494 \n",
      "\n",
      "----------------------------------------------------------\n",
      "model no.2 \n",
      "Inner score: 0.607576 VS Outer score: 0.721519 \n",
      "\n",
      "----------------------------------------------------------\n",
      "Features selected: \n",
      "\n",
      "None\n",
      "[[ 1461.  1462.  1463.  1464.  1465.  1466.  1467.  1468.  1469.  1470.]\n",
      " [ 1461.  1462.  1463.  1464.  1465.  1466.  1467.  1468.  1469.  1470.]]\n"
     ]
    }
   ],
   "source": [
    "# Nested CV in order to evaluate the models' expected performance\n",
    "# Since feature selection and normalization are a part of the model's\n",
    "# construction, they should be performed inside the CV to avoid over-optimistic\n",
    "# errors. Normalizing the whole dataset leaks future information to the estimators\n",
    "# thus, you should only normalize the train set and then use mean and std to normalize\n",
    "# test/val set. In that regard, the inner training set is normalized, its params are used\n",
    "# on the inner test set and then the outer training set is normalized accordingly\n",
    "\n",
    "struct = [\n",
    "      [ {'gamma': np.arange(0.02,5,0.5), 'C':[0.1, 1, 10]},\n",
    "       {'n_neighbors' : [2, 5, 10, 15]},\n",
    "       {'alpha': [0.0001, 0.01, 0.1, 1], 'hidden_layer_sizes': [(100,100), (50,)]}\n",
    "      ],\n",
    "      [SVC(C=10), \n",
    "       KNeighborsClassifier(),\n",
    "       MLPClassifier()]]\n",
    "# struct = [\n",
    "#     [], [KNeighborsClassifier()]\n",
    "# ]\n",
    "classifiers = struct[1]\n",
    "\n",
    "# X,y = X[2,0], Y[2]\n",
    "x_tot = np.copy(X[2]) ; y_tot = np.copy(Y[2])\n",
    "x_tot = x_tot[0: :50] ; y_tot = y_tot[0: :50]\n",
    "\n",
    "# x_tot = np.copy(X[1,1,2])\n",
    "# y_tot = np.copy (Y[1])  \n",
    "# x_tot = np.copy(Xsonar)\n",
    "# y_tot = np.copy(ysonar)\n",
    "\n",
    "n_outer_folds = 5\n",
    "n_inner_folds = 5\n",
    "state = 42 \n",
    "nfeat = 10 # number of features to keep\n",
    "ncomp = 5 # number of components to keep \n",
    "n_top_models = 2 # define the number of bests ranking classifiers\n",
    "\n",
    "best_feat_ind = np.zeros((n_top_models,nfeat))\n",
    "\n",
    "outer_scores = np.zeros((n_top_models, n_outer_folds)) \n",
    "\n",
    "#list containing all the clf and their respective pipelines\n",
    "pipeline = [make_pipe(clf, sca = StandardScaler(), order = 1) for clf in classifiers]\n",
    "\n",
    "#outer loop i.e. the one that evaluates the inner \"best\" model\n",
    "outer_kfold = StratifiedKFold(n_splits = n_outer_folds, shuffle = True, random_state = state)\n",
    "outer = outer_kfold.split(x_tot,y_tot)\n",
    "# list containing the best 'n_top_models' for each fold \n",
    "best_pipes = [[],[]]\n",
    "\n",
    "for fold_out, (train_ind_out, test_ind_out) in enumerate(outer):\n",
    "    top_classifiers = []\n",
    "    print(\"Outer loop %d/%d\" %((fold_out + 1), n_outer_folds))\n",
    "    \n",
    "    # split the dataset \n",
    "    x_trn_out, x_tst_out = x_tot[train_ind_out], x_tot[test_ind_out]\n",
    "    y_trn_out, y_tst_out = y_tot[train_ind_out], y_tot[test_ind_out]  \n",
    "\n",
    "    inner_scores = np.zeros((len(classifiers),n_inner_folds))\n",
    "    inner_mean_scores = np.zeros(len(classifiers))\n",
    "    inner_scores2 = np.zeros((len(classifiers),n_inner_folds))\n",
    "    inner_mean_scores2 = np.zeros(len(classifiers))\n",
    "\n",
    "    for cl_ind,clf in enumerate(classifiers):\n",
    "        \n",
    "        inner_kfold = StratifiedKFold( n_splits = n_inner_folds, shuffle = True, random_state = state)\n",
    "        inner = inner_kfold.split(x_trn_out, y_trn_out)\n",
    "\n",
    "        for fold_in, (train_ind_in, test_ind_in) in enumerate(inner): \n",
    "            print(\"Inner fold %d/%d\" % ((fold_in + 1), n_inner_folds ))\n",
    "            # split the datasets for the inner cv \n",
    "            x_trn_in, x_tst_in = x_trn_out[train_ind_in], x_trn_out[test_ind_in]\n",
    "            y_trn_in, y_tst_in = y_trn_out[train_ind_in], y_trn_out[test_ind_in]\n",
    "            \n",
    "            pip = pipeline[cl_ind].fit(x_trn_in,y_trn_in)\n",
    "            inner_scores[cl_ind][fold_in] = pip.score(x_tst_in, y_tst_in)\n",
    "                 \n",
    "    # get the mean performance for every classifier\n",
    "    inner_mean_scores = np.mean(inner_scores, axis = 1)\n",
    "    print('\\n',inner_mean_scores)\n",
    "    \n",
    "    # sort the scores, low -> high \n",
    "    sorted_inds = inner_mean_scores.argsort()\n",
    "    sorted_scores = inner_mean_scores[sorted_inds]\n",
    "    \n",
    "    print (\"Best %d models for outer fold %d are: \\n \" %(n_top_models, (fold_out+1)))\n",
    "    \n",
    "    #get the inds of best performing models\n",
    "    temp2 = 0\n",
    "    for temp_ind in range(-1, -(n_top_models +1), -1):\n",
    "        actual_ind = sorted_inds[temp_ind]\n",
    "        best_pipes[1].append(pipeline[actual_ind]) \n",
    "        best_pipes[0].append(fold_out)\n",
    "        print(\"model no.%d \"%actual_ind)\n",
    "        print(pipeline[actual_ind].named_steps['clf'])\n",
    "        #print the top features selected\n",
    "        best_fs = pipeline[actual_ind].named_steps['feature_selection']\n",
    "        pipe_fs_unsorted = best_fs.scores_\n",
    "        fs_inds = pipe_fs_unsorted.argsort()\n",
    "        pipe_fs = pipe_fs_unsorted[fs_inds]\n",
    "        temp3 = 0 # temp3 = 0:number of features\n",
    "        \n",
    "        for temp_ind2 in range(-1, -(nfeat +1), -1):         \n",
    "            best_feat_ind[temp2][temp3] = fs_inds[temp_ind2]\n",
    "            temp3+=1\n",
    "            \n",
    "        #fit the best classifier on the outer test data\n",
    "        pipeline[actual_ind].fit(x_trn_out, y_trn_out)\n",
    "        #get the outer score \n",
    "        outer_scores[temp2, fold_out] = pipeline[actual_ind].score(x_tst_out, y_tst_out)\n",
    "        print(\"Inner score: %f VS Outer score: %f \\n\" %(inner_mean_scores[actual_ind], outer_scores[temp2, fold_out]))\n",
    "        print (\"----------------------------------------------------------\")\n",
    "        temp2+=1\n",
    "\n",
    "        \n",
    "    print(\"Features selected: \\n\")\n",
    "#     print(best_feat_ind.sort())     \n",
    "    print(best_feat_ind)\n",
    "# print(outer_scores)  \n",
    "# print(best_pipes)\n",
    "winsound.Beep(400,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nfeat = 20\n",
    "ncomp = 5\n",
    "clas = SVC(C = 10)\n",
    "xp = np.copy(X[1]) ; yp = np.copy(Y[1])\n",
    "xp = xp[0: :10] ; yp = yp[0: :10]\n",
    "# plt.hist(yp)\n",
    "prip = make_pipe(clf = clas,order=1, sca= StandardScaler())\n",
    "prip.fit(X[1],Y[1])\n",
    "winsound.Beep(400,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ela pasaka mou: 0.688492\n",
      "Normalized confusion matrix\n",
      "[[ 0.59272727  0.40727273]\n",
      " [ 0.19650655  0.80349345]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.59      0.67       275\n",
      "        1.0       0.62      0.80      0.70       229\n",
      "\n",
      "avg / total       0.71      0.69      0.69       504\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAEmCAYAAAAN9HleAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa827382e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_t = np.copy(X[0]) ; y_t = np.copy(Y[0])\n",
    "x_t = x_t[0: :20] ; y_t = y_t[0: :20]\n",
    "prd_l = prip.predict(x_t)\n",
    "cnf = confusion_matrix(y_t,prd_l)\n",
    "print(\"ela pasaka mou: %f\" %prip.score(x_t,y_t))\n",
    "prip_clf = prip.named_steps['classifier']\n",
    "plot_confusion_matrix(cm = cnf, classes = prip_clf.classes_)\n",
    "print(classification_report(y_t,prd_l))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=1, score=0.803922, total=  20.7s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.8s remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=1, score=0.862745, total=  20.3s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   41.2s remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=1, score=0.784314, total=  20.4s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.0min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=1, score=0.840000, total=  20.1s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=1, score=0.780000, total=  20.8s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.7min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=1, score=0.803922, total=  22.8s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.1min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=1, score=0.843137, total=  23.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.5min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=1, score=0.803922, total=  23.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.9min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=1, score=0.840000, total=  22.6s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  3.2min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=1, score=0.800000, total=  24.1s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  3.7min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=1, score=0.823529, total=  19.8s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  4.0min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=1, score=0.803922, total=  19.7s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  4.3min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=1, score=0.843137, total=  20.6s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  4.7min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=1, score=0.840000, total=  20.4s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  5.0min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=1, score=0.780000, total=  21.8s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  5.4min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=1, score=0.803922, total=  21.2s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  5.7min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=1, score=0.725490, total=  22.4s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  6.1min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=1, score=0.784314, total=  19.7s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  6.4min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=1, score=0.760000, total=  20.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  6.8min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=1 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=1, score=0.720000, total=  19.7s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  7.1min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=10, score=0.843137, total=  19.3s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  7.4min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=10, score=0.901961, total=  19.3s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  7.7min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=10, score=0.764706, total=  19.4s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=10, score=0.880000, total=  19.7s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  8.4min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=auto, classifier__C=10, score=0.820000, total=  19.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  8.7min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=10, score=0.843137, total=  19.1s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  9.0min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=10, score=0.882353, total=  19.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  9.4min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=10, score=0.803922, total=  18.9s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  9.7min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=10, score=0.860000, total=  19.1s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed: 10.0min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.05, classifier__C=10, score=0.800000, total=  19.6s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 10.3min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=10, score=0.823529, total=  19.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed: 10.6min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=10, score=0.803922, total=  19.1s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 11.0min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=10, score=0.862745, total=  19.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed: 11.3min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=10, score=0.820000, total=  19.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed: 11.6min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=0.2, classifier__C=10, score=0.780000, total=  19.0s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed: 11.9min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=10, score=0.803922, total=  19.1s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 12.2min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=10, score=0.745098, total=  19.2s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed: 12.6min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=10, score=0.784314, total=  19.3s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed: 12.9min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=10, score=0.760000, total=  19.1s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed: 13.2min remaining:    0.0s\n",
      "[CV] feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=10 \n",
      "[CV]  feature_selection__k=1000, decomp__n_components=50, classifier__gamma=2, classifier__C=10, score=0.720000, total=  19.7s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 13.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 13.5min finished\n",
      "------ Grid search cv results for SVM ------\n",
      "Best score: 0.8419\n",
      "Best parameters set:\n",
      "\tclassifier__C: 10\n",
      "\tclassifier__gamma: 'auto'\n",
      "\tdecomp__n_components: 50\n",
      "\tfeature_selection__k: 1000\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "x_tot = np.copy(X[1]) ; y_tot = np.copy(Y[1])\n",
    "x_tot = x_tot[0: :40] ; y_tot = y_tot[0: :40]\n",
    "# plt.hist(y_tot)\n",
    "# print(y_tot.shape)\n",
    "# x_tot = Xsonar ; y_tot = ysonar\n",
    "#Grid search for param tuning in SVM()\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "grid_pip = make_pipe(clf = SVC(), sca = StandardScaler(), order = 1)\n",
    "# params = {'feature_selection__k': (33,12),\n",
    "#          'decomp__n_components': (11,4),\n",
    "#           'classifier__gamma' : ('auto',0.02, 0.2, 2),\n",
    "#           'classifier__C': (1,10,100),\n",
    "#          }\n",
    "params = {'feature_selection__k': np.array([1000]),\n",
    "         'decomp__n_components':np.array([50]),\n",
    "          'classifier__gamma' : ('auto', 0.05,0.2, 2),\n",
    "          'classifier__C': (1,10),\n",
    "         }\n",
    "grid_search = GridSearchCV(grid_pip, params, verbose = 1000, cv = cv)\n",
    "grid_search.fit(x_tot, y_tot)\n",
    "print(\"------ Grid search cv results for SVM ------\")\n",
    "print(\"Best score: %0.4f\" %grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(params.keys()):\n",
    "     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "winsound.Beep(400,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('feature_selection', SelectKBest(k=100,\n",
       "      score_func=<function mutual_info_classif at 0x0000009717697268>)), ('decomp', PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "  svd_solver='auto', to...',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model selected above to the whole training data\n",
    "best_pip = make_pipe(clf = SVC(), sca = StandardScaler(), order = 1)\n",
    "params = {'feature_selection__k': (100),\n",
    "         'decomp__n_components': (100),\n",
    "          'classifier__gamma' : ('auto'),\n",
    "          'classifier__C': (10),\n",
    "         }\n",
    "best_pip.set_params(**params)\n",
    "# weighted_clf = make_pipe(clf = SVC(), sca = StandardScaler(), order = 1)\n",
    "# weighted_clf.set_params(**params)\n",
    "\n",
    "x_ftrain, y_ftrain = np.copy(X[1]), np.copy(Y[1])\n",
    "x_ftrain = x_ftrain[0: :40] ; y_ftrain = y_ftrain[0: :40]\n",
    "\n",
    "best_pip.fit(x_ftrain,y_ftrain)\n",
    "# weighted_clf.fit(x_ftrain,y_ftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.706349206349\n",
      "Normalized confusion matrix\n",
      "[[ 0.64963504  0.35036496]\n",
      " [ 0.22608696  0.77391304]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.65      0.71       137\n",
      "        1.0       0.65      0.77      0.71       115\n",
      "\n",
      "avg / total       0.72      0.71      0.71       252\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAEmCAYAAADx4VKUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcb4YcHRGGP8sOBojDF+/D94ncGYLNTn1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x97ae8876d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ftest, y_ftest = np.copy(X[0]),np.copy(Y[0])\n",
    "x_ftest = x_ftest[0: :40] ; y_ftest = y_ftest[0: :40]\n",
    "\n",
    "print(best_pip.score(x_ftest, y_ftest))\n",
    "predicted_labels = best_pip.predict(x_ftest)\n",
    "cmf = confusion_matrix(y_ftest,predicted_labels)\n",
    "best_pip_clf = best_pip.named_steps['classifier']\n",
    "plt.figure(0)\n",
    "plot_confusion_matrix(cm = cmf, classes = best_pip_clf.classes_)\n",
    "\n",
    "# print(weighted_clf.score(x_ftest, y_ftest))\n",
    "# predicted_labels2 = weighted_clf.predict(x_ftest)\n",
    "# cmf2 = confusion_matrix(y_ftest, predicted_labels2)\n",
    "# weighted_clf_clf = weighted_clf.named_steps['classifier']\n",
    "# plt.figure(1)\n",
    "# plot_confusion_matrix(cm = cmf2, classes = weighted_clf_clf.classes_, title = 'weighted')\n",
    "\n",
    "\n",
    "print(classification_report(y_ftest,predicted_labels))\n",
    "# print(classification_report(y_ftest, predicted_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "http://stackoverflow.com/questions/35388647/how-to-use-gridsearchcv-output-for-a-scikit-prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
